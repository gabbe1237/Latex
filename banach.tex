\documentclass{article}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\setlength{\parindent}{0pt}
\usepackage[table]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{pgfplots}
\usepackage{pst-plot}
% \usepackage{fdsymbol}
\usepackage{empheq}
\usepackage{tikz}
\usepackage[most]{tcolorbox}
\usepackage{enumerate}
\usepackage{scalerel}
\usepackage{relsize}
\usepackage{mdframed}
\usepackage[utf8]{inputenc}
\usetikzlibrary{shapes}

\usetikzlibrary{calc,patterns,angles,quotes}
\definecolor{myblue}{rgb}{2.55, 1.50, 0.20}
% \definecolor{myblue}{RGB}{227, 234, 253}
\newtcbtheorem[number within=subsection]{mytheo}{Sats}%
    {colback=myblue!15,colframe=black!30!black,
     enhanced,
     coltitle=black!75!black, boxrule=0.8pt,
     attach boxed title to top left=
       {xshift=2ex,yshift=-2mm,yshifttext=-1mm},
     boxed title style={colframe=black!30!black, boxrule=0.8pt,
       colback=myblue!60}}{th}

       
\newtcbtheorem[number within=subsection]{mydef}{Definition}%
    {colback=myblue!15,colframe=black!30!black,
     enhanced,
     coltitle=black!75!black, boxrule=0.8pt,
     attach boxed title to top left=
       {xshift=2ex,yshift=-2mm,yshifttext=-1mm},
     boxed title style={colframe=black!30!black, boxrule=0.8pt,
colback=myblue!60}}{th}

\newtcbtheorem[number within=subsection]{mykol}{Korollarium}%
    {colback=myblue!15,colframe=black!30!black,
     enhanced,
     coltitle=black!75!black, boxrule=0.8pt,
     attach boxed title to top left=
       {xshift=2ex,yshift=-2mm,yshifttext=-1mm},
     boxed title style={colframe=black!30!black, boxrule=0.8pt,
colback=myblue!60}}{th}

\newtcbtheorem[number within=subsection]{mylemma}{Lemma}%
    {colback=myblue!15,colframe=black!30!black,
     enhanced,
     coltitle=black!75!black, boxrule=0.8pt,
     attach boxed title to top left=
       {xshift=2ex,yshift=-2mm,yshifttext=-1mm},
     boxed title style={colframe=black!30!black, boxrule=0.8pt,
colback=myblue!60}}{th}

\newtcbtheorem[number within=subsection]{myaxiom}{Axiom}%
    {colback=myblue!15,colframe=black!30!black,
     enhanced,
     coltitle=black!75!black, boxrule=0.8pt,
     attach boxed title to top left=
       {xshift=2ex,yshift=-2mm,yshifttext=-1mm},
     boxed title style={colframe=black!30!black, boxrule=0.8pt,
colback=myblue!60}}{th}

% ---------------------------------------------
% ---------------RE-NEW COMMAND----------------
% ---------------------------------------------
\newcommand\mul[1]{\multicolumn{1}{c}{#1}}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.2}
\renewcommand*{\proofname}{Bevis}
\newcommand{\ovning}[1]{\noindent {\bf Övning #1.}}
\renewcommand{\contentsname}{Innehåll}
\newcommand{\orbit}[0]{\mathcal{O}}
\newtheorem{definition}{Definition}[section]
\pgfplotsset{compat=1.8}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{exmp}[thm]{Exempel}

\parindent0mm
\setlength{\parskip}{1ex}
\addtolength{\headheight}{2pt}
\setlength{\textheight}{25cm}

\setlength{\topmargin}{-25mm}

\setlength{\textwidth}{18cm}
\setlength{\hoffset}{0cm}
\setlength{\oddsidemargin}{-5mm}
\setlength{\marginparwidth}{-0mm}
\setlength{\evensidemargin}{-5mm}

\begin{document}
% \pagecolor[HTML]{fefcf5}
% \pagecolor[HTML]{fffae6}
% ---------------------------------------------
% ---------------FÖRSTA SIDAN------------------
% ---------------------------------------------
% \title{Banach-Tarski paradoxen}z
\begin{figure}
  \begin{center}
    \newcommand{\mydistance}{.6cm}
    \vspace{4cm}
    \begin{tikzpicture}[node distance=2cm, scale=1]
      \draw[fill=myblue!60] (-2.5,2.5) rectangle (2.5,-2.5);
      % \shade[ball color = gray, opacity = 0.5] (0,0) circle (3cm);
      \node (infinity)[scale=4] at (0, 0){\Large{$\mathbf{\infty}$}};
      % \draw (0,0) circle (3cm);
      % \draw (-2,0) arc (180:360:2 and 0.6);
      % \draw[dashed] (2,0) arc (0:180:2 and 0.6);
      % \fill[fill=black] (0,0) circle (1pt);
      % \draw[dashed] (0,0 ) -- node[above]{$r$} (2,0);
      
    \end{tikzpicture}
  \end{center}  
\end{figure}

\title{%
  Banach-Tarski paradoxen \\
  \small{En introduktion till det abstrakta - Del I}
}
\author{Gabriel Rajkowski}
\date{12 mars, 2021}
\maketitle
\begin{center}
  \begin{tabular}{l r}
  Skola: & Europaskolan \\ 
  Program: & Scienceprogrammet \\ 
  Handledare: & Johan Wild
  \end{tabular}
\end{center}

\maketitle

\thispagestyle{empty}

\clearpage
\tableofcontents
\section{Inledning}
Banach-Tarski paradoxen är en paradox uppkallad efter två polska matematiker Stefan Banach och Alfred Tarski
som påstår att en sfär i ett tredimensionellt rum kan sönderdelas till ändligt antal bitar
där dessa bitar sedan kan sättas ihop på ett sådant sätt att två identiska kopior av originalet erhålls. Syftet med denna text är 
inte bara att bevisa detta, men även att ge läsaren en översikt i olika matematiska områden där gruppteori är huvudfokuset.
Frågorna som denna text försöker besvara på är om denna paradox fungerar i högre dimensioner, om man kan tillämpa detta på cirklar, om paradoxen 
medför att man kan skapa en sfär i en dimension större än den man började med och om paradoxen är tillämpbar i den verkliga världen.
Inga matematiska förkunskaper krävs för att läsa och förstå viktiga delar i denna text. Det är dock bra om läsaren är matematiskt mogen 
och är bekant med definitioner, bevis och axiomer. Denna text, speciellt avsnittet om gruppteori, är en förkunksap för del II
där Galoisteori och mer abstrakt algebra tas upp.


% Syfte: Ta upp grunderna inom mängdlära, linjär algebra och gruppteori (med huvudfokus på gruppteori) 
% så att läsaren ska känna sig tillräckligt matematisk mogen för att läsa vidare om mer avancerade grejer inom abstrakt algebra.
% Syftet är även att bevisa Banach-Tarski paradoxen och ta upp detaljerna som andra källor, till exempel wikipedia, inte tar upp.

% Frågeställningar: Går det att duplicera en cirkel istället för en sfär (ganska trivial)?
% Går det att göra om en 2-sfär (2-sphere, "3D sfär") till en 3-sfär ("4D sfär")
% (ganska trivial)? Fungerar Banach-Tarski paradoxen i högre dimensioner (ganska trivial)?
% Dessa ovannämnda frågeställningar skulle jag kunna besvara på direkt i sektionen
% om Banach-Tarski paradoxen direkt efter beviset. En annan lämplig frågeställning skulle 
% kunna vara "Går det att förstå paradoxen utan att använda matematik?". Här 
% skulle jag kunna visa ett oformellt, men intuitivt, bevis av paradoxen utan att 
% använda matematik överhuvudtaget. 

\section{Mängdlära}
Mängdläran studerar mängder och är en av matematikens grundstenar. 
\linebreak
Mängläraren är egentligen inte en del av
matematiken utan snarare en förutsättning för matematiken, vilket gör den intressant att studera.

En \textit{mängd} (eng. \textit{set}) är helt enkelt en samling av objekt eller \textit{element} där repetition 
inte förekommer och ordningen inte har någon betydelse.
Dessa element kan vara vad som helst, vänner, bilar, nummer eller så kan dem själva vara mängder. 
Ett exempel på en mängd är 
\[S = \{\clubsuit, \diamondsuit, \spadesuit, \heartsuit\}\]
och vi skriver
\[\clubsuit, \diamondsuit, \spadesuit, \heartsuit \in S\]
för att indikera att $\clubsuit, \diamondsuit, \spadesuit, \heartsuit$ tillhör $S$.
Ibland kan mängder också vara tomma, det vill säga $\{ \}$. En sådan mängd kallas för en \textit{tom mängd} och 
betecknas med $\emptyset$. \textit{Kardinaliteten} av en mängd är storleken, det vill säga 
hur många element som finns i den, och betecknas med absolutbelopp. 
Kardinaliteten av exempelvis $S$ ges av
$|S| = 4$ och kardinaliteten av den tomma mängden är självklart noll. 

Mängder behöver dock inte alltid vara ändliga. 
Nedanför följer exempel på oändliga och vanliga mängder som majoriteten redan har 
stött på.
\begin{align*}
    \mathbb{N} & = \{0, 1, -1, 2, -2, \ldots \}, \\
    \mathbb{Z^+} & = \{1, -1, 2, -2, 3, -3, \ldots \}, \\
    \mathbb{Q} & = \{\frac{1}{2}, \ldots, -3, \ldots, 4, \ldots \}.
\end{align*}

Vi ser direkt att de rationella talen $\mathbb{Q}$ blir krångliga att skriva som en mängd. I 
dessa fall så kan man ta hjälp av \textit{mängdbyggare} för att beteckna en mängd. 
Ett bättre sätt 
att skriva de rationella talen med hjälp av mängdbyggare är på följande vis
\[ \mathbb{Q} = \biggl\{ \frac{m}{n} \; \biggl| \; m, n \in \mathbb{Z} \land n \neq 0 \biggl\}\]
som med ord blir \textit{mängden av de rationella talen innehåller $\frac{m}{n}$ så att $m, n$ är heltal och 
$n$ får inte vara noll.} Kort sagt så finner man
alltid elementen på vänstra sidan om $|$ och kriterierna som elementen måste uppfylla på högra sidan när man 
använder denna notation. Som exempel så kan man skriva mängden av alla jämna tal på följande vis
\[2 \mathbb{Z} = \{x \; | \; x = 2n, n \in \mathbb{Z}\} = \{0, 2, -2, 4, -4, \ldots\}.\]
Alla saker på mitt skrivbord kan också beskrivas som en mängd. Denna mängd kan skrivas som
\[ \textnormal{alla saker på mitt skrivbord} = \{x \; | \; x \in \textnormal{ mitt skrivbord}\}. \]
Vi definiera nu vad en delmängd är.

\begin{mydef}{}{}
  Mängden $A$ är en \textit{delmängd} (eng. \textit{subset}) av mängden $B$ om alla element i $A$ ingår även i $B$. Detta skrivs 
  $A \subseteq B$. Om $A \subseteq B$ och $A \neq B$ så är $A$ en \textit{äkta delmängd} (eng. \textit{proper subset}) av $B$ och skrivs
  $A \subset B$.
\end{mydef}
Vi ser direkt att $\emptyset \subseteq A$ för varje mängd $A$ och att varje mängd är en delmängd av 
sig själv. Definitionen medför även att om 
$A \subseteq B$ och $B \subseteq A$ så måste $A = B$, vilket vi kommer att använda vid senare tillfällen för bevisföring. 

\begin{exmp}
Mängden $A = \{1, 2\}$ är en 
äkta delmängd av $B = \{1, 2, 3, 4\}$ eftersom alla element som finns i $A$ finns även i $B$ och 
$A \neq B$. Därimot så
är $B$ inte en delmängd av $A$ eftersom $B$ innehåller element som inte finns i $A$.
\end{exmp}
 
Det går 
även att skriva dessa delmängder i "kedjor", till exempel 
$\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}$, som
bilden nedan försöker illustrera. 


%ta upp disktjunkta mängder

\begin{center}
  \begin{tikzpicture}
    \draw (0,0) ellipse (3cm and 2.5cm);
    \draw (0.4,0) ellipse (2.5cm and 2cm);
    \draw (0.7,0) ellipse (2cm and 1.5cm);
    \draw (0.8,0) ellipse (1.5cm and 1cm);
    \draw (1,0) ellipse (1cm and 0.5cm);
    \node[] at (-2.5,0) {$\mathbb{C}$};
    \node[] at (-1.7,0) {$\mathbb{R}$};
    \node[] at (-1,0) {$\mathbb{Q}$};
    \node[] at (-0.3,0) {$\mathbb{Z}$};
    \node[] at (1,0) {$\mathbb{N}$};
  \end{tikzpicture}
\end{center}

\subsection{Mängdoperationer}
Vi definiera nu några vanliga mängdoperationer som kommer att användas genom hela texten. 

\begin{mydef}{}{}
  \textit{Unionen} (eng. \textit{union}) av två mängder $A$ och $B$ är mängden av element som finns i 
  $A$ \textbf{eller} $B$ och betecknas med $\cup$. Med symboler blir definitionen
  \[A \cup B \equiv \{x \; | \; x \in A \; \lor \; x \in B  \}.\]
  Om $\mathpzc{A}$ är en mängd vars element är mängder så är $\bigcup \mathpzc{A}$ unionen
  av alla element i $\mathpzc{A}$. 
\end{mydef}

\begin{center}
  \begin{tikzpicture}
    \begin{scope} [fill opacity = .4]
      \draw[fill=red, draw = black] (-1,0) circle (1.5);
      \draw[fill=red, draw = black] (1,0) circle (1.5);
    \end{scope}
    
    \draw (-3.5,2) rectangle (3.5,-2);
    \node at (-3,1) {\LARGE\textbf{A}};
    \node at (3,1) {\LARGE\textbf{B}};
    % \node at (0,0) {\LARGE\textbf{O}};

      % \draw[help lines](-5,5) grid (5,-6);  
  \end{tikzpicture}
\end{center}
Det hela röda området i venn diagramet visar $A \cup B$. Man kan alltså tänka att unionen
av två mängder sammansätter de två mängderna.
\begin{exmp}
  Låt $A = \{1, 2, 3\}$ och $B = \{3, 4, 5\}$. Då är $A \cup B = \{1, 2, 3, 4, 5\}$ 
  eftersom repetition inte förekommer i mängder.   
\end{exmp}
För en union av flera mängder $A_1, A_2, \ldots, A_n$
kan det ibland bli jobbigt att skriva $A_1 \cup A_2 \cup \ldots \cup A_n$. Därför har man infört 
en ny beteckning för detta, nämligen $\bigcup\limits_{i=1}^{n} A_i$. 
% Om 
% $\mathpzc{A}$ istället är en mängd där elementen är mängder 
% (en sådan mängd brukar betecknas med en "fin" bokstav) så är $\bigcup 
% \mathpzc{A}$ unionen av alla element i $\mathpzc{A}$. 

\begin{mydef}{}{}
  \textit{Snittet} (eng. \textit{intersection}) av två mängder $A$ och $B$ är mängden av element som finns i $A$ \textbf{och} $B$ och
  betecknas med $\cap$. Med symboler blir definitionen
  \[A \cap B \equiv \{x \; | \; x \in A \; \land \; x \in B  \}.\]
  Om $\mathpzc{A}$ är en mängd vars element är mängder så är $\bigcap \mathpzc{A}$ 
  snittet av alla element i  $\mathpzc{A}$.
\end{mydef}

\begin{center}
  \begin{tikzpicture}
    \begin{scope} [fill opacity = .4]
      \draw[fill=blue, draw = black] (-1,0) circle (1.5);
      \draw[fill=magenta, draw = black] (1,0) circle (1.5);
    \end{scope}
    
    \draw (-3.5,2) rectangle (3.5,-2);
    \node at (-3,1) {\LARGE\textbf{A}};
    \node at (3,1) {\LARGE\textbf{B}};
    \node at (0,0) {\textbf{$A \cap B$}};

      % \draw[help lines](-5,5) grid (5,-6);  
  \end{tikzpicture}
\end{center}
Det lila området där cirklarna överlappar i venn diagramet visar $A \cap B$. Snittet 
av två mängder är alltså mängden av alla gemensamma element. 
\begin{exmp}
  Låt $A$ och $B$ vara mängder som förekom i förra exemplet, då är $A \cap B = \{3\}$.
\end{exmp}
Även här har man infört en ny beteckning för att slippa skriva mycket. Istället 
för att skriva $A_1 \cap A_2 \cap \ldots \cap A_n$ så kan man skriva $\bigcap\limits_{i = 1}^n A_n$.
% Om $\mathpzc{A}$ istället är en mängd vars element är mängder så är $\bigcap \mathpzc{A}$ snittet 
% av alla element i  $\mathpzc{A}$.

\begin{mydef}{}{}
  \textit{Differensen} (eng. \textit{relative complement}) av två mängder $A$ och $B$ är mängden av element som finns i $A$ 
  men som inte finns i $B$. Detta
  betecknas med $\setminus$ och utläses "$A$ utom $B$". Med symboler blir definitionen 
  \[A \setminus B \equiv \{x \; | \; x \in A, \; x \notin B  \}\]
\end{mydef}

\begin{center}
  \begin{tikzpicture}
    \begin{scope} [fill opacity = .4]
      \draw[fill=blue, draw = black] (-1,0) circle (1.5);
      \draw[fill=magenta, draw = black] (1,0) circle (1.5);
    \end{scope}
    
    \draw (-3.5,2) rectangle (3.5,-2);
    \node at (-3,1) {\LARGE\textbf{A}};
    \node at (3,1) {\LARGE\textbf{B}};
    \node at (-1.3,0) {\textbf{$A \setminus B$}};

      % \draw[help lines](-5,5) grid (5,-6);  
  \end{tikzpicture}
\end{center}
Endast det blåa området (och inte det lila området där cirklarna överlappar) i venn diagramet
visar $A \setminus B$. Differensen mellan två mängder $A$ och $B$ är alltså mängden av element
som är unika i $A$. 

Notera att differensen mellan två mängder inte är kommutativ, det vill säga 
$A \setminus B \neq B \setminus A$.
\begin{exmp}
  Låt $A$ och $B$ vara mängder som förekom i förra exemplet, då är $A \setminus B
  = \{1, 2\}$.  
\end{exmp}
Det finns såklart fler operationer som kan utföras på mängder men 
\linebreak
dessa utelämnas i denna 
text. 
Operationerna som har tagits upp är de vanligaste och endast dessa kommer 
att användas framöver. Två saker till bör dock definiera innan detta del avsnitt avslutas. 

\begin{mydef}{}{}
  Två mängder $A$ och $B$ är \textit{disjunkta} (eng. \textit{disjoint}) om $A \cap B = \emptyset$. Om $\mathpzc{A}$ är 
  en mängd vars element är mängder så är $\mathpzc{A}$ \textit{parvis disjunkt} om $\bigcap \mathpzc{A} = 
  \emptyset$.
\end{mydef}
I ett venn diagram (Euler diagram) så skulle alltså $A$ och $B$ inte överlappa varandra
om det var disjunkta. 
\begin{exmp}
  Mängderna $A = \{1, 2, 3\}$ och $B = \{4, 5\}$ 
  är disjunkta eftersom $A$ och $B$ inte har några gemensamma element. 
  Om 
  \[\mathpzc{A} = \{\{1, 2, 3\}, \{4, 5, 6\}, \{7, 8, 9\}\ldots\}\] 
  så är $\mathpzc{A}$ parvis disjunkt eftersom alla element i mängden 
  inte har några gemensamma element. 
\end{exmp}

\begin{mydef}{}{}
  En \textit{partition} (eng. \textit{partition}) av en mängd $A$ är en mängd av icke-tomma delmängder av $A$ sådant att 
  varje element i $A$ endast förekommer en gång i dessa delmängder. 
  Partitionen av $A$ måste alltså vara parvis disjunkt.
\end{mydef}
%flytta alla exempel längdst ned??
\begin{exmp}
  Låt $A = \{1, 2, 3\}$. Denna mängd kan ha fem olika partitioner, nämligen
\begin{itemize}
  \item $\{\{1\}, \{2\}, \{3\}\}$,
  \item $\{ \{1, 2\}, \{3\} \}$,
  \item $\{ \{1, 3\}, \{2\} \}$,
  \item $\{ \{1\}, \{2, 3\} \}$.
  \item $\{ \{1, 2, 3\} \}$
\end{itemize}
Medan $ P = \{ \{\}, \{1, 2\}, \{4, 3, 2\} \}$ inte är en partition av $A$ på grund av några anledningar, $P$ innehåller en tom mängd, mängden $\{4, 3, 2\}$ är inte en delmängd till $A$
och $P$ är inte heller parvis disjunk, $\bigcap P = \{2\} \neq \emptyset$. Notera att det endast räcker med att nämna en av dessa anledningar för att visa att $P$ inte är en partition av $A$.
\end{exmp}

\subsection{Tuplar och ordnade par}
\begin{mydef}{Tuplar och ordnade par}{}
  En $n$\textit{-tupel} (eng. \textit{tuple}) är en sekvens innehållande $n$ styckna olika objekt, $(n_0, n_1, n_2, \ldots, n_n)$, där ordningen mellan dem spelar roll. Dessa objekt
  kallas för \textit{komponenter}. Ett \textit{ordnat par} (eng. \textit{ordered pair}) är ett annat namn för en 2-tupel.
\end{mydef}
Notera att en $n$-tupel skiljer sig från en mängd eftersom ordningen har betydelse.
\begin{exmp}
  (DAG, MÅNAD, ÅR) är en 3-tupel 
  eftersom den innehåller 
  en sekvens som består av tre styckna object där ordningen har betydelse. 
\end{exmp}

\begin{exmp}
  Punkter i ett kartesiskt eller polärt koordinatsystem är ordnade par
  eftersom för två olika $x$ och $y$ så är punkten $(x, y) \neq (y, x)$. 
\end{exmp}
% För bevisföring inom mängdläran 
% så kan man använda sig av Kuratowskis definition av ordande par som säger att 
% $(a, b) = \{ \{a\}, \{a, b\} \}$. 

\subsection{Kartesiska produkter}

\begin{mydef}{Kartesiska produkter}{}
  Den \textit{kartesiska produkten} av två mängder $A$ och $B$ är mängden av alla ordnade par $(a, b)$
  där $a \in A$ och $b \in B$. Kartesiska produkten tecknas med $A \times B$ och utläses "$A$ kryss $B$".
  Med symboler blir definitionen
  \[A \times B \equiv \{(a, b) \; | \; a \in A, \; b \in B\}.\]
\end{mydef}
%onödigt med detta. Ha kvar detta nedan om jag ska ha övningar i min text, eller ta bort 
%den så att läsaren får klura ut detta själv. 
Lägg märke till att $|A \times B|=|A| \cdot |B|$ eftersom varje elementen i $A$
måste accosieras med varje elementen i $B$.

\begin{exmp}
  Låt $A = \{13, 37, 0\}$ och $B = \{4, 2\}$. Då är
\[A \times B = \{ (13, 4), (13, 2), (37, 4), (37, 2), (0, 4), (0, 2) \},\]
medan 
\[B \times A = \{ (4, 13), (4, 37), (4, 0), (2, 13), (2, 37), (2, 0) \}.\]
Vi ser att $A \times B \neq B \times A$ eftersom ordningen
har betydelse i ordade par och därför är den kartesiska produkten inte kommutativ. 
\end{exmp}
För att konstruera en mängd med $3$-tuplar så kan följande göras.
\[A \times B \times C = \{ (a, b, c) \; | \; a \in A, \; b \in B, \; c \in C \},\]
där $A, B$ och $C$ är mängder. Detta konceptet kan generaliseras till $n$-tuplar. 
Den kartesiska produkten ger oss även ett sätt att "skapa" fler dimensioner.
%ett annat ord för skapa kanske?
$\mathbb{R} \times \mathbb{R}$ är alla möjliga ordnade par av de reella talen och skapar därför det 
tvådimensionella Euklidiska rummet $\mathbb{R}^2$. På samma sätt kan man skapa det tredimensionella Euklidiska rummet,
$\mathbb{R} \times \mathbb{R} \times \mathbb{R} = \mathbb{R}^3$, och konceptet kan generaliseras till 
$\mathbb{R}^n$. 
\[\mathbb{R}^n = \{(x_1, x_2, x_3, \ldots, x_n) \; | \; x_i \in \mathbb{R} \textnormal{ för } 1 
\leq i \leq n\; \} \].


% ta även upp att R X R är R^2 osv. här så att jag slipper göra det i linjär algebra delen.
\subsection{Axiomatiska system och Russells paradox}
Ibland kan det uppkomma olika paradoxer med mängder om man inte är försiktig. Det stora problemet 
ligger för det mesta att elementen i en mängd kan själva vara mängder. För att demonstrera en sådan 
paradox så kan vi ta Russells paradox som utvecklades under 1800-talet av den italienska logikern Burali-Forti
och senare av Bertrand Russell. 

Vi börjar med att definiera en mängd $S$ som består av alla mängder $X$ sådana att $X$ inte innehåller 
$X$. Med symboler kan vi skriva denna mängd som
\[S = \{X \; | \; X \textnormal{ är en mängd och } X \notin X  \}. \]
För att åstadkomma paradoxen så ställer vi frågan om $S$ innehåller sig själv eller inte. 
Vi antar först att $S \in S$.
För att $S$ ska vara ett element av $S$ så 
måste $S$, per definition, vara en mängd och $S \notin S$.
Vi antog dock att $S \in S$, vilket betyder att $S \notin S$. Vi konstruerade dock $S$ på ett sådant sätt att om $S \notin S$ så betyder det samtidigt att $S \in S$ och vi hamnar i ett
cirkelresonemang på liknande vis som vid "påståendet" "detta påstående är falskt".

För att undvika dessa paradoxer så har tanken om mängdlära som ett axiomatiskt system växt fram. 
Idag finns det flera sådana system, till exempel Zermelo–Fraenkel systemet ($\mathsf{ZF}$). Det vanligaste 
systemet är Zermelo–Fraenkel systemet kombinerat med Urvalsaxiomet ($\mathsf{ZFC}$). Detta avnsitt har inte använts sig 
av ett sådant system eftersom det inte varit nödvändigt. 
Urvalsaxiomet (eng. Axiom of Choice, $\mathsf{AC}$) kommer dock att 
tas upp och diskuteras senare i texten.

\section{Funktioner}
För att förstå viktiga koncept inom gruppteori så måste vi definiera en funktion mer formellt och ta upp detaljer som man vanligtvist soppar under mattan i en vanlig gymnasiekurs.

\begin{mydef}{Funktioner}{}
  En \textit{funktion} $f$ från den icke tomma mängden $X$, \textit{definitionsmängden}, till den icke tomma mängden $Y$, \textit{målmängden}, är definierad 
  av en mängd $G$ av ordnade par $(x, y), x \in X, y \in Y$ så att $x$ är den första komponenten i \textbf{exakt ett} ordnat par i $G$ för att $x$. En funktion $f$ från mängden $X$
  till mängden $Y$ betecknas
  \[f: X \rightarrow Y.\]
  Om $(x, y) \in G$ så är $y$ värdet av $f$ av $x$ och skrivs $y=f(x)$. Mängden av alla möjliga utvärden av funktionen, det vill säga mängden av alla $f(x)$, är funktionens \textit{värdemängd}.
\end{mydef}

En funktion enligt denna definition är alltså en regel som till varje element i definitionsmängden kopplar alla element i värdemängden. Om definitionsmängden och värdemängden endast innehåller
tal så brukar man kunna beskriva denna regel med en matematisk formell, till exempel $f(x) = x^2$.

Intuitivt så är funktionen $f(x) = x^2$ en slags "maskin". Man stoppar in ett element från definitionsmängden i funktionen och på ett magiskt sätt 
så kommer det ut ett annat tal. Formellt så associerar,
eller \textit{mappar}, en funktion ett element från definitionsmängden till ett korresponderande element från målmängden.


\begin{center}
  \begin{tikzpicture}
    \draw (0,0) ellipse (1cm and 1.5cm);
    \node at (0,1) {$x_1$};
    \node at (0,0) {$x_2$};
    \node at (0,-1) {$x_3$};
    \node at (0, 2) {$X$};

    \draw (4,0) ellipse (1cm and 1.5cm);
    \node at (4,1) {$y_1$};
    \node at (4,0) {$y_2$};
    \node at (4,-1) {$y_3$};
    \node at (4, 2) {$Y$};

    \draw [-latex, thick] (0.2, 1) -- (3.8, 1);
    \draw [-latex, thick] (0.2, 0) -- (3.8, 0);
    \draw [-latex, thick] (0.2, -1) -- (3.8, -1);

    \node at (2,1.5) {"mappar"};

    \node[scale=1.3] at (2, 3) {$f: X \rightarrow Y$};
  \end{tikzpicture}
\end{center}

De två cirklarna i figuren ovanför skall föreställa två mängder $X$ och $Y$. En funktion 
från $X$ till $Y$ mappar alltså ett element $x \in X$ med ett korresponderande element $y \in Y$
vilket skrivs $f: x \mapsto y$ och är ett annat sätt att definiera denna funktion på istället för $f(x) = y$.
Funktionen definieras i detta fall av mängden $G = \{ (x_1, y_1), (x_2, y_2), (x_3, y_3) \}$ och dess 
definitionsmängd är $X = \{ x_1, x_2, x_3\}$ och målmängden är identisk med värdemängden, det vill säga $Y = \{ y_1, y_2, y_3\}.$ 

\begin{exmp}
  Betrakta funktionen $f(x) = x^2$ för $x \in \mathbb{R}$. Denna funktion mappar 
  ett reellt tal $x$ med $x^2$, vilket skrivs 
  $f: x \mapsto x^2$
  och är ett annat sätt att definiera funktionen på.
  Eftersom funktionen mappar ett reellt tal med ett annat reellt tal så är definitionsmängden
  och målmängden $\mathbb{R}$, det vill säga 
  $f: \mathbb{R} \rightarrow \mathbb{R}.$
  Värdemängden är alla möjliga utvärden av funktionen och eftersom kvadraten av ett reellt tal alltid 
  är positivt så är värdemängden alla positiva reella tal. 
  Mängden som definierar $f(x) = x^2$ är
  $G = \{ (x, x^2) \; | \; x \in \mathbb{R}\}.$  
\end{exmp}

\begin{exmp}
  Vi avgör nu om $y^2 = x, \; x \in \mathbb{R}$ är en funktion eller inte. 
  Mängden 
  som definierar denna ekvation är $G = \{ (x^2, x) \; | \; x \in \mathbb{R} \}.$
  För att denna ekvation ska vara en funktion
  så måste $x^2, \; x \in \mathbb{R}$ vara den första komponanten i \textbf{exakt ett} ordnat par i $G$.
  Vi ser att $(1^2, 1) \in G$ och att $((-1)^2, -1) = (1^2, -1) \in G$. 
  $1^2$ förekommer i två ordnade par som den första komponenten och därför är 
  $y^2 = x$ inte en funktion.  
\end{exmp}

Notera att funktioner inte behöver gå från tal till tal. Definitionsmängden och målmängden är 
mängder och kan därför innehålla massor av olika saker. En funktion kan till exempel 
mappa en geometrisk figur med en färg, ett ansiktsuttryck med en känsla osv. 

\subsection{Bijektion, injektion och surjektion}
\begin{mydef}{}{}
  Låt oss definiera funktionen
  \[f: X \rightarrow Y.\]
  \begin{itemize}
    \item $f$ är \textit{injektiv} om alla element i $Y$ är mappade med \textbf{högst}
    ett element från $X$, det vill säga det finns högts ett $x \in X$ så att $f(x) = y, \; y \in Y.$
    Med symboler och för bevisföring
    \[\forall x, x' \in X, f(x) = f(x') \implies x = x'.\]
    \item $f$ är \textit{surjektiv} om alla element från 
    $Y$ är mappade med \textbf{åtminstone} ett element från $X$, det 
    vill säga det finns åtminstone ett $x \in X$ så att $f(x) = y, \; y \in Y.$
    Med symboler och för bevisföring
    \[\forall y \in Y, \exists x \in X \; | \; y = f(x).\]
    \item $f$ är \textit{bijektiv} om alla element från värdemängden är mappade med \textbf{exakt} 
    ett element från definitionsmängden. Funktionen är alltså både injektiv och surjektiv.
    Med andra ord så existerar det endast ett $x \in X$ så att $f(x) = y, \; y \in Y.$
  \end{itemize}
\end{mydef}

\begin{exmp}
  Ellipserna i figuren nedan föreställer mängder.
\end{exmp}
\begin{center}
  \begin{tikzpicture}[scale = 0.7]
    \draw (0,0) ellipse (1cm and 1.5cm);
    \node at (0, 1) {$x_1$};
    \node at (0, 0) {$x_2$};
    \node at (0, -1) {$x_3$};
    \draw (3,0) ellipse (1cm and 1.5cm);
    \node at (3, 1) {$y_1$};
    \node at (3, 0) {$y_2$};
    \node at (3, -1) {$y_3$};
    \draw [-latex] (0.2, 1) -- (2.8, 1);
    \draw [-latex] (0.2, 0) -- (2.8, 0);
    \draw [-latex] (0.2, -1) -- (2.8, -1);
    \node at (1.5, -2) {Bijektiv};

    \draw (7,0) ellipse (1cm and 1.5cm);
    \node at (7, 1) {$x_1$};
    \node at (7, 0) {$x_2$};
    \node at (7, -1) {$x_3$};
    \draw (10,0) ellipse (1cm and 1.5cm);
    \node at (10, 1) {$y_1$};
    \node at (10, 0.3) {$y_2$};
    \node at (10, -0.4) {$y_3$};
    \node at (10, -1.1) {$y_4$};
    \draw [-latex] (7.2, 1) -- (9.8, 1);
    \draw [-latex] (7.2, 1) -- (9.8, 0.3);
    \draw [-latex] (7.2, 0) -- (9.8, -0.4);
    \draw [-latex] (7.2, -1) -- (9.8, -1.1);
    \node at (8.5, -2) {Ingen funktion};

    \draw (0,4) ellipse (1cm and 1.5cm);
    \node at (0, 5) {$x_1$};
    \node at (0, 4) {$x_2$};
    \node at (0, 3) {$x_3$};
    \draw (3,4) ellipse (1cm and 1.5cm);
    \node at (3, 5) {$y_1$};
    \node at (3, 4.3) {$y_2$};
    \node at (3, 3.6) {$y_3$};
    \node at (3, 2.9) {$y_4$};
    \draw [-latex] (0.2, 5) -- (2.8, 5);
    \draw [-latex] (0.2, 4) -- (2.8, 3.6);
    \draw [-latex] (0.2, 3) -- (2.8, 2.9);
    \node at (1.5, 2) {Injektiv};

    \draw (7,4) ellipse (1cm and 1.5cm);
    \node at (7, 5) {$x_1$};
    \node at (7, 4.3) {$x_2$};
    \node at (7, 3.6) {$x_3$};
    \node at (7, 2.9) {$x_4$};
    \draw (10,4) ellipse (1cm and 1.5cm);
    \node at (10, 5) {$y_1$};
    \node at (10, 4) {$y_2$};
    \node at (10, 3) {$y_3$};
    \draw [-latex] (7.2, 5) -- (9.8, 5);
    \draw [-latex] (7.2, 4.3) -- (9.8, 5);
    \draw [-latex] (7.2, 3.6) -- (9.8, 4);
    \draw [-latex] (7.2, 2.9) -- (9.8, 3);
    \node at (8.5, 2) {Surjektiv};

    % \draw (-1, 6) rectangle (8, -2.4);
  \end{tikzpicture}
\end{center}

\begin{exmp}
Säg att vi vill visa att funktionen $f: \mathbb{R} \rightarrow \mathbb{R}$ som definieras av 
$f(x) = x^2$ inte är injektiv. Vi kan först anta motsatsen, att $f$ är injektiv. Per definition får vi då att för alla reella $x$ och $x'$ som uppfyller $f(x) = f(x')$
så medför detta att $x = x'$. Vi ser dock att $x^2 = x'^2$ vilket medför att $x = \pm x'$ vilket betyder att $x$ inte behöver vara lika med $x'$. Detta strider mot vårat antagande och
därför kan $f$ inte vara injektiv.

Vi kan även visa att samma funktion inte är surjektiv. Funktionen är surjektiv om för alla reella $y$ så existerar det ett motsvarande reellt $x$ så att $y=f(x)$. För 
att visa att $f$ inte är surjektiv så räcker det alltså med att hitta ett reellt $y$ så att $y \neq f(x) \iff y \neq x^2$. Ett exempel på ett sådant $y$ är $y = -1$ eftersom $x^2$
alltid är positivt coh kan därför inte vara $-1$. För att göra $f: \mathbb{R} \rightarrow \mathbb{R}$ surjektiv så kan vi begränsa målmängden $\mathbb{R}$ till värdemängden $\mathbb{R}^+$.

\end{exmp}

Vi kan nu ställa upp följande sats som blir användbar vid senare tillfällen. 
\hypertarget{kompbij}{}
\begin{mytheo}{}{}
  Låt $f: Y \rightarrow Z$ och $g: X \rightarrow Y$ vara bijektioner. Då är $f(g(x)), x \in X$ 
  också en bijektion.
\end{mytheo}
\begin{proof}
  Vi visar först att $f(g(x))$ är injektiv. Genom en logisk modifiering (kontraposition) av symbolvarianten 
  så är en funktion injektiv om
  \[ \forall x, x' \in X, x \neq x' \implies f(x) \neq f(x'). \]
  Låt $x, x' \in X$ sådana att $x \neq x'.$ Eftersom $g$ är bijektiv och därför också injektiv 
  så gäller $g(x) \neq g(x')$. I och med att $f$ är injektiv så gäller $f(g(x)) \neq f(g(x'))$
  och alltså är $f(g(x))$ injektiv.

  Vi går vidare och visar att $f(g(x))$ är surjektiv. Vi vill alltså visa att 
  \[\forall z \in Z, \exists x \in X \; | \; z = f(g(x)).\]
  $g$ är bijektiv och därför även surjektiv vilket betyder att det existerar 
  ett $x \in X$ sådant att $u = g(x)$ för $u \in Y.$ Vidare är $f$ surjektiv och därför 
  måste $f(u) = f(g(x)) = z$ för alla $z \in Z$ och därför är $f(g(x))$ surjektiv.
  
  $f(g(x))$ är alltså bijektiv som ett resultat av att $f(g(x))$ både är injektiv och surjektiv. 
\end{proof}

\subsection{Inverser}
\begin{mydef}{}{}
  En funktion $f^{-1}: Y \rightarrow X$ är \textit{inversen} till funktionen 
  $f: X \rightarrow Y$ om för $x \in X$ så gäller $f^{-1}(f(x)) = x$ och $f(f^{-1}(x)) = x.$ 
\end{mydef}
Varje bijektion har givetvis en invers och det är uppenbart att en funktion som endast 
är surjektiv eller injektiv inte kan ha någon invers på grund av hur vi definierar funktioner. Dessutom så är det självklart att inversen 
till en bijektion också är en bijektion men för säkerhets skull så bevisar vi detta. 
\hypertarget{invbij}{}
\begin{mytheo}{}{}
  Inversen till en bijektion $f: X \rightarrow Y$ är också en bijektion.
\end{mytheo}
\begin{proof}
  Vi visar först att inversen är injektiv. Låt $y$ och $y'$ vara element i $Y$ sådana att 
  $f^{-1}(y) = f^{-1}(y')$ vilket medför $f(f^{-1}(y)) = f(f^{-1}(y'))$ och per definition 
  får vi att $y = y'$ och inversen är på så sätt injektiv.

  Vi visar att inversen är surjektiv.
  Låt $x \in X$. Vi ska alltså visa att det existerar ett $y \in Y$ så att 
  $x = f^{-1}(y) \implies f(x) = f(f^{-1}(y)) \implies f(x) = y.$ Eftersom 
  $f$ är en bijektion från $X$ till $Y$ och $x \in X$ så måste det existera ett $y$ för 
  varje $x$ och därfär är inversen surjektiv. 
  
  Inversen är både surjektiv och injektiv vilket gör den bijektiv.
\end{proof}

\section{Linjär algebra}
Detta avsnitt är en liten introduktion till linjär algebra. Linjär algebra studerar vektorer, vektorrum 
(linjära rum), linjära ekvationssystem och linjära transformationer. För oss är det endast nödvändigt 
att förstå linjära transformationer så att vi kan rotera olika punkter i $\mathbb{R}^3$. För att förstå 
vad en linjär transformation är så måste vi först ta upp grunderna inom linjär algebra. 

% lär dig lite mer om linjär algebra. 
\subsection{Vektorer}
\begin{mydef}{}{}
  En \textit{vektor} i $\mathbb{R}^n$ är en lista av $n$ styckna tal som kallas \textit{komponenter}. 
\end{mydef}
Notera att denna definition inte är helt matematisk formell. Du får olika definitioner beroende på vem du frågar, frågar du en fysiker så får du att en vektor
är något som har en storlek och riktning, frågar du en matematiker så får du (oftast) att en vektor är ett element av ett 
vektorrum och om du frågar en datavetenskapare så får du vår 
definition. Denna variant fungerar dock utmärkt för detta lilla delmoment och den formella definitionen tas upp i del II. 

Det finns åtminstone två olika sätt att tolka en vektor i $\mathbb{R}^n$ med våran definition. Det första är som en 
punkt där komponenterna anger koordinaterna för punkten. Det andra sättet är att tänka en vektor 
som något som har en storlek och en rikting. Genom att tänka på detta sätt så kan man illustrera en 
vektor med en riktad pil som pekar från en valfri punkt till en slutpunkt som ges av komponenterna.
I detta avnsitt kommer vi att rita vektorer på precis detta sätt. 

Det finns olika beteckningar för vektorer men på grund av senare skäl
så kommer vi beteckna en vektor med en pil över en liten bokstav och omringa komponenterna 
med hakparenteser. Man kan lägga komponenterna både horisontellt och vertikalt. Om komponenterna
sitter horisontellt så kallas vektorn för en \textit{radvektor} och om komponenterna sitter 
vertikalt så kallas vektorn för en \textit{kolonnvektor}.
\begin{exmp}
  Vektorn
\[\vec{a} = 
\begin{bmatrix}
  2 \\
  3 \\
\end{bmatrix} = [2, 3]
\]
tillhör $\mathbb{R}^2$ och dess komponenter är 2 och 3. 
Man kan illustrera denna vektor grafiskt 
genom att rita en pil från origo till slutpunkten $(2, 3)$ i ett kartesiskt koordinatsystem.
\begin{center}
  \begin{tikzpicture}[scale = 0.6]
    \draw[help lines, color=gray] (-3.9,-3.9) grid (3.9,3.9);
    \draw[->, thick] (-4,0)--(4,0) node[right]{$x$};
    \draw[->, thick] (0,-4)--(0,4) node[above]{$y$};

    \node[] at (0.5,2) {$\vec{a}$};
    \node[] at (-2.5,2.5) {$\vec{a}$};
    % \draw [fill=blue] (A) circle (2pt) node [left] {A};
    % \draw [fill=blue] (B) circle (2pt) node [left] {B};
    
    \draw [-latex, red, thick] (0, 0) -- (2, 3);
    \draw [-latex, red, thick] (-3, 1) -- (-1, 4);
  \end{tikzpicture}
\end{center}
I figuren ovanför så ser vi två lämpliga illustrationer av vektorn $\vec{a}$. Den ena börjar i origo
och har sin endpunkt vid (2, 3) och den andra börjar i (-3, 1) och slutar i (-1, 4). Man får alltså 
"flytta" runt sin vektor så länge riktingen och storleken (längden) blir oförändrade. 
\end{exmp}

%kanske en riktig definition här??
Addition och multiplikation av en skalär (slarvigt sagt en konstant) 
har också definierats.
För att addera två vektorer numeriskt så adderar 
man korresponderande komponenter med varandra. 
Låt exempelvis $\vec{a} = [-2, 5]$ och $\vec{b} = [6, 1]$, 
då är 
\[\vec{a} + \vec{b} = [-2 + 6, 5 + 1] = [4, 6].\]
För att multiplicera en skalär
med en vektor så multiplicerar man varje komponent med den skalären,
\[c \cdot \vec{a} = [-2 \cdot c, 5 \cdot c].\]
Det grafiska resultatet av dessa operationer lämnas som ett 
litet experiment till läsaren. 
Notera att vi kan subtrahera två vektorer genom att multiplicera den ena vektorn med 
$-1$ och sedan addera dem. 
% RITA KANSKE EN GRAF, BEROENDE PÅ OM JAG KOMMER HA PLATS MED DET!
% För en grafisk visualisering av addition och subtrahion så sätter man vektorerna i följd på varandra.
\begin{mydef}{}{}
  \textit{Skalärprodukten} mellan två vektorer $a$ och $b$ i $\mathbb{R}^n$ 
  betecknas $\langle \vec{a}, \vec{b} \rangle$ och ges av
  \[\langle \vec{a}, \vec{b} \rangle \equiv [a_1, a_2, \ldots, a_n] 
  \begin{bmatrix}
    b_1 \\
    b_2 \\
    \vdots \\
    b_n
  \end{bmatrix} = a_1 b_1 + a_2 b_2 + \ldots + a_n b_n.
  \]
\end{mydef}
Anledningen till varför den ena vektorn är horisontell och den andra vertikal är för att 
underlätta senare koncept. Båda vektorerna kan alltså vara horisontella eller vertikala 
om man så önksar. 
\begin{exmp}
  Betrakta vektorerna $\vec{a} = [-2, 5]$ och $\vec{b} = [6, 1]$. 
  Skalärprodukten av $\vec{a}$ och $\vec{b}$ ges då av
  \[\langle \vec{a}, \vec{b} \rangle = [-2, 5] 
\begin{bmatrix}
  6 \\
  1
\end{bmatrix} = -2 \cdot 6 + 5 \cdot 1 = -7.
\]  
\end{exmp}

Notera att skalärprodukten bara kan utföras på två vektorer om de har samma längd. 
Skalärprodukten mellan en vektorer i till exempel $\mathbb{R}^3$ och en annan vektor i $\mathbb{R}^2$
är alltså odefinierad eftersom det saknas korresponderande element. 

Eftersom skalärprodukten bara adderar produkter så blir resultatet alltid en skalär, vilket 
är förklaringen till namnet \textit{skalärprodukt}. 


\subsection{Matriser}
\begin{mydef}{}{}
  En $matris$ är ett rektangulärt schema av tal, symboler eller uttryck anordnade i rader och kolumner. 
  Dessa tal eller andra storheter i en matris kallas för \textit{element}.  
\end{mydef}
% -----------------------------------
%FLYTTA DELEN UNDER KOMMENTAREN LÄNGRE NER NÄR MAN HAR FÅTT EN INBLICK TILL VAD EN MATRIS ÄR.
% -----------------------------------
Viktigt att inse är att 
matriser inte är något naturligt matematiskt fenomen, 
utan ett sätt att lagra andra matematiska fenomen.
Till exempel så kan matriser vara användbara vid programering eller datorgrafik för att lagra data som 
pixlar på en skärm eller liknande. Vi ser också att vektorer egentligen bara är ett specialfall av en 
matris.
\begin{exmp}
Matrisen
\[ \underset{2 \times 3}{A} = 
  \begin{bmatrix}
    1 & 2 & 3 \\
    x & y & z
  \end{bmatrix}
\]
är en $2 \times 3$ matris och har alltså två rader och tre kolumner.
I denna matris så är $1, 2, 3, x, y$ och $z$ element i $\underset{2 \times 3}{A}.$
Det är inte nödvändigt att ange dimensionerna nedanför variablen, det är valfritt. 

För att uttrycka ett element i denna matris så anger man i vilken rad och kolumn 
elementet befinner sig i som ett nedre index. Till exempel så är 
$A_{21} = x$ och $A_{13} = 3$.
\end{exmp}

Operationer på matriser har också definierats. För att addera två matriser så adderar man helt enkelt korresponderande element med varandra. 
Låt exempelvis 
\[ A = 
  \begin{bmatrix}
    7 & -2 & 13 \\
    4 & 0 & 9
  \end{bmatrix}, \;
  B = 
  \begin{bmatrix}
    1 & 6 & -2 \\
    6 & 10 & 2
  \end{bmatrix}.
\]

Då är 
\begin{align*}
  A + B & =
  \begin{bmatrix}
    7 + 1 & -2 + 6 & 13 + (-2) \\
    4 + 6 & 0 + 10 & 9 + 2
  \end{bmatrix} \\
  & = 
  \begin{bmatrix}
    8 & 4 & 11 \\
    10 & 10 & 11
  \end{bmatrix}.
\end{align*}
För kunna addera två matriser så måste de alltså ha samma 
dimensioner. Till exempel så går det inte att 
addera $\underset{3 \times 1}{A}$ med $\underset{4 \times 4}{B}$ eftersom vissa element i den ena matrisen saknar ett korresponderande element i den andra matrisen.

För att multiplicera en skalär med en matris så multiplicerar man 
alla element i matrisen med den skalären. Vi låter $A$ vara samma matris som förut och $c$ en skalär.
Då är 
\[
c \cdot A = 
  \begin{bmatrix}
    7 \cdot c & -2 \cdot c & 13 \cdot c \\
    4 \cdot c & 0 \cdot c & 9 \cdot c
  \end{bmatrix}.
\]
För att multiplicera två matriser med varandra så blir det lite jobbigare. 
Istället för att definiera multiplikation på liknande sätt som addition så har man valt att definiera det lite annorlunda. Det har helt enkelt visat sig vara väldigt praktiskt med just
denna definition.

Vi väljer två "slumpmässiga" matriser $A$ och $B$, säg
\[
A = \begin{bmatrix}
  3 & 1 & 2 \\
  -1 & 0 & 5
\end{bmatrix}, \; 
B = 
\begin{bmatrix}
  -1 & 3 \\
  2 & 5 \\
  6 & 7
\end{bmatrix},
\]
och multiplicerar dem med varandra
\[A \times B = 
  \left[ 
  \;
  \begin{array}{cccc}
    \rowcolor{blue!20}
    3 & 1 & 2 \\
    \rowcolor{red!20}
    -1 & 0 & 5
  \end{array}
  \;
  \right]
  \left[
  \;
  \begin{array}{>{\columncolor{green!20}}c>{\columncolor{orange!40}}cc}
    1 & 3 \\
    2 & 5 \\
    6 & 7
  \end{array}
  \;
  \right].
\]
För att göra det enklare för oss så färglägger vi alla rader i $A$ och alla kolumner i $B$ med olika 
färger. Vi kan tänka oss att de färgglada områderna representerar vektorer. Vi namnger nu dessa 
"vektorer"/områden
baserat på vilken färg de har, \textcolor{blue!60}{$B$}
för det blåa området, \textcolor{red!60}{$R$} för det röda, \textcolor{green!70!black}{$G$} för det gröna och 
\textcolor{orange!60}{$O$} för det orangea. Definitionen av matris multiplikation lyder att 
\[A \times B = 
\begin{bmatrix}
  \langle \textcolor{blue!60}{B}, \textcolor{green!70!black}{G} \rangle &
  \langle \textcolor{blue!60}{B}, \textcolor{orange!60}{O} \rangle \\
  \langle \textcolor{red!60}{R}, \textcolor{green!70!black}{G} \rangle &
  \langle \textcolor{red!60}{R}, \textcolor{orange!60}{O} \rangle
\end{bmatrix}.
\]
För att få fram några vettiga element för $A \times B$ så måste vi utföra dessa skalärprodukter. 
\begin{align*}
  \langle \textcolor{blue!60}{B}, \textcolor{green!70!black}{G} \rangle &= 
  3 \cdot 1 + 1 \cdot 2 + 2 \cdot 6 = 17,\\
  \langle \textcolor{blue!60}{B}, \textcolor{orange!60}{O} \rangle &= 
  3 \cdot 3 + 1 \cdot 5 + 2 \cdot 7 = 28, \\
  \langle \textcolor{red!60}{R}, \textcolor{green!70!black}{G} \rangle &=
  -1 \cdot 1 + 0 \cdot 2 + 5 \cdot 6 = 29, \\
  \langle \textcolor{red!60}{R}, \textcolor{orange!60}{O} \rangle &=
  -1 \cdot 3 + 0 \cdot 5 + 5 \cdot 7 = 32,
\end{align*}
och därför blir 
\[A \times B =
\begin{bmatrix}
  17 & 28 \\
  29 & 32
\end{bmatrix}.
\]
Vi ser att multiplikation av två matriser endast kan ske om den första matrisen har lika många kolumner
som den andra har rader. Till exempel så kan man multiplicera $\underset{2 \times 3}{A}$ med 
$\underset{3\times 2}{B}$ men inte $\underset{2 \times 4}{A}$ med $\underset{3 \times 3}{B}$ eftersom 
skalärprodukten bara kan utföras på två vektorer om de har samma längd.

För att bevisa att multiplikation av matriser inte är kommutativ så kan man 
beräkna $B \times A$ och jämföra resultatet med $A \times B$. Detta lämnas som en övning till läsaren.

\begin{mydef}{Identitetsmatrisen}{}
  \textit{Identitetsmatrisen} är en $n \times n$ matris som har ettor längst diagonalen (från övre vänstra 
  till nedre högra hörnet) och nollor överallt annars och betecknas med $I_n,$
  \[\underset{n \times n}{I_n} =
  \left[
  \;
  \begin{array}{>{\columncolor{green!20}}c>{\columncolor{orange!40}}cc
    >{\columncolor{blue!20}}c}
    1 & 0 & \cdots & 0 \\
    0 & 1 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    0 & 0 & \cdots & 1
  \end{array}
  \;
  \right].
  \]
  Varje kolumn i identitetsmatrisen har fått en beteckning, det gröna området 
  betecknas med $\vec{e}_1$, det orangea med $\vec{e}_2$ och det blåa med $\vec{e}_n$ och därför är 
  $I_n = [\vec{e}_1, \vec{e}_2, \ldots, \vec{e}_n].$
\end{mydef}

\begin{exmp}
  Matrisen 
  \[
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
  \end{bmatrix}
  \]
  är identitetsmatrisen $I_3$ och består av 
  \[ \vec{e}_1 = 
  \begin{bmatrix}
    1 \\
    0 \\
    0
  \end{bmatrix}, 
  \vec{e}_2 = 
  \begin{bmatrix}
    0 \\
    1 \\
    0
  \end{bmatrix},
  \vec{e}_3 = 
  \begin{bmatrix}
    0 \\
    0 \\
    1
  \end{bmatrix}
  \]
  och därför är $I_3 = [\vec{e}_1, \vec{e}_2, \vec{e}_3].$
\end{exmp}

En viktig egenskap hos identitetsmatriserna är att 
\[\underset{m \times n}{A} I_n = \underset{m \times n}{A} = I_m \underset{m \times n}{A}\]
vilket enkelt kan visas genom att multiplicera matriserna. 



\subsection{Linjära transformationer}
En \textit{transformation} är egentligen bara en funktion. Man ger funktionen en mängd och funktionen 
mappar alla element med ett korresponderande element från en annan mängd. I linjär algebra brukar man 
dock tänka att en transformation mappar en vektor med en annan vektor. Anledningen till namnet 
\textit{transformation} och inte \textit{funktion} sitter i visualiseringen. Man kan tänka att en 
transformation "gör om", eller transformerar, 
en vektor till en annan vektor genom att till exempel rotera den, göra 
den längre eller liknande. En transformation brukar betecknas med ett $T$. 

\begin{exmp}
  Betrakta transformationen $T: \mathbb{R}^3 \rightarrow \mathbb{R}^2$ som definieras av 
\[T \left(
  \begin{bmatrix}
    x_1 \\
    x_2 \\
    x_3
  \end{bmatrix}
\right) = 
\begin{bmatrix}
  x_1 + x_2 \\
  x_3 x_2 
\end{bmatrix}.
\]
För att kolla vad denna transformation gör med en vektor 
så kan vi välja en slumpmässig vektor i $\mathbb{R}^3$, säg
\[\vec{v} = 
\begin{bmatrix}
  1 \\
  2 \\
  1
\end{bmatrix}
\]
och sedan kolla på vad $T(\vec{v})$ blir. 
\[T(\vec{v}) = 
\begin{bmatrix}
  1 + 2 \\
  1 \cdot 2
\end{bmatrix} = 
\begin{bmatrix}
  3 \\
  2
\end{bmatrix}.
\]

\begin{center}
  \begin{tikzpicture}
    \draw (0,0,0) --  (2,0,0)  node[pos=1.05]{$x$};
    \draw (0,0,0) -- (0,3,0) node[pos=1.05]{$y$};
    \draw (0,0,0) -- (0,0,2) node[pos=1.1]{$z$};

    \draw [-latex, red, thick] (0, 0, 0) -- (1, 2, 1);
    \draw[dashed, red, thick] (0, 0, 0) -- (1, 0, 1);
    \draw[dashed, red, thick] (1, 0, 1) -- (1, 2, 1);
    \node[scale = 1] at (1, 2.3, 1) {$(1, 2, 1)$};

    \draw [-latex] (2.7, 1, 0) -- (4.3, 1, 0);
    \node at (3.5, 1.5, 0) {$T(\vec{v})$};

    \draw (5, 0) -- (7, 0) node[pos=1.05] {$x$};
    \draw (5, 0) -- (5, 2) node[pos=1.05] {$y$};
    \draw [-latex, red] (5, 0) -- (6.5, 1);
    \node at (6.5, 1.4) {$(3, 2)$};
  \end{tikzpicture}
\end{center}
I figuren ovan ser vi visuellt hur vektorn $v$ transformeras av $T$. 
\end{exmp}

En \textit{linjär} transformation är inget mer än en vanlig transformation som måste uppfylla två villkor. 

\hypertarget{linjarT}{}
\begin{mydef}{Linjära transformationer}{}
  En \textit{linjär transformation} mellan $\mathbb{R}^n$ och $\mathbb{R}^m$ (mer generellt
  mellan två vektorrum) är en transformation $T: \mathbb{R}^n \rightarrow \mathbb{R}^m$
  där följande villkor uppfylls
  \begin{enumerate}[(i)]
    \item $T(\vec{v_1} + \vec{v_2}) = T(\vec{v_1}) + T(\vec{v_2}),$
    \item $cT(\vec{v_1}) = T(c \vec{v_1}),$
  \end{enumerate}
  för två vektorer $\vec{v_1}, \vec{v_2}$ 
     i $\mathbb{R}^n$ och en skalär $c.$
\end{mydef}
Med hjälp av linjära transformationer så kan vi ställa upp följande sats som blir användbar senare. 

\hypertarget{linjarTsats}{}
\begin{mytheo}{}{}
  En linjär transformation $T: \mathbb{R}^n \rightarrow \mathbb{R}^m$ kan representeras 
  som 
  \[T(\vec{v}) = [ \; T(\vec{e}_1), \; T(\vec{e}_2), \ldots, \; T(\vec{e}_n) \;] \vec{v}\]
  för en vektor $\vec{v} \in \mathbb{R}^n$ och där $\vec{e}_1, \vec{e}_2, \ldots, \vec{e}_n \in I_n$
\end{mytheo}
\begin{proof}
  Låt $\vec{v}$ vara en vektor i $\mathbb{R}^n$ definierad som
  \[\vec{v} = 
  \begin{bmatrix}
    v_1 \\
    v_2 \\
    \vdots \\
    v_n
  \end{bmatrix},
  \]
  då gäller det att 
  \[
    v = I_n v = [\vec{e}_1, \; \vec{e}_2, \ldots, \; \vec{e}_n] 
    \begin{bmatrix}
      v_1 \\
      v_2 \\
      \vdots \\
      v_n
    \end{bmatrix} = \vec{e}_1 v_1 + \vec{e}_2 v_2 + \cdots + \vec{e}_n v_n 
  \]
  \[\iff\]
  \[
    T(v) = T(\vec{e}_1 v_1 + \vec{e}_2 v_2 + \cdots + \vec{e}_n v_n).
  \]
    Eftersom $T$ är en linjär transformation så måste den uppfylla villkoren I och II enligt
  \hyperlink{linjarT}{definition 4.3.1}. Vid användning av (i) får vi 
  \[T(v) = T(\vec{e}_1 v_1) + T(\vec{e}_2 v_2) + \cdots + T(\vec{e}_n v_n)\]
  och sedan av (ii)
  \begin{align*}
    T(v) &= v_1 T(\vec{e}_1) + v_2 T(\vec{e}_2) + \cdots + v_n T(\vec{e}_n) \\
    &= [ \; T(\vec{e}_1) +  T(\vec{e}_2) + \cdots +  T(\vec{e}_n) \;]
    \begin{bmatrix}
      v_1 \\
      v_2 \\
      \vdots \\
      v_n
    \end{bmatrix} \\
    &=  [ \; T(\vec{e}_1) +  T(\vec{e}_2) + \cdots +  T(\vec{e}_n) \;] \vec{v}.
  \end{align*}
\end{proof}


%kanske bättre att ha med \textbf{exempel 3.1} blablalbla. 


\subsubsection{Rotationer i \texorpdfstring{$\mathbb{R}$$^3$}{}}
Detta avsnitt kommer att kolla på en speciell linjär transformation, nämligen en rotation
kring $x, y$ och $z-$axeln. Beviset av att en rotation är en linjär transformation är inte 
särskilt interesant och inte heller elegant, så det kommer att utelämnas i denna text. Vi får 
helt enkelt ta det som givet för denna stund. (Det visar sig att varje linjär transformation kan uttryckas som en matris. 
Då rotationer kan uttryckas med matriser så måste rotationer vara linjära transformationer. Detta argument håller dock inte i beviset nedan
då vi först antar att rotationer är linjära transformationer för att komma fram till att rotationer är linjära transformationer).

För att beteckna en rotation moturs med $\theta$ 
kommer $Rot_{x\theta}$, $Rot_{y\theta}$ och $Rot_{z\theta}$ användas för att indikera vilken 
axel vi roterar krign.
Vi börjar med att ställa upp följande sats

\hypertarget{sats5.3.2}{}
\begin{mytheo}{}{}
  En moturs rotation $Rot_{n\theta} : \mathbb{R}^3 \rightarrow \mathbb{R}^3, \; n \in \{x, y, z\}$ 
  med $\theta$ i $\mathbb{R}^3$ av en vektor $\vec{v} \in \mathbb{R}^3$ ges av 
  \begin{align}
    Rot_{x\theta} (\vec{v}) &= 
    \begin{bmatrix}
      1 & 0 & 0 \\
      0 & \cos(\theta) & -\sin(\theta) \\
      0 & \sin(\theta) & \cos(\theta)
    \end{bmatrix} \vec{v}, \\
    Rot_{y\theta} (\vec{v}) &= 
    \begin{bmatrix}
      \cos(\theta) & 0 & \sin(\theta) \\
      0 & 1 & 0 \\
      -\sin(\theta) & 0 & \cos(\theta)
    \end{bmatrix} \vec{v}, \\
    Rot_{z\theta} (\vec{v}) &= 
    \begin{bmatrix}
      \cos(\theta) & -\sin(\theta) & 0 \\
      \sin(\theta) & \cos(\theta) & 0 \\
      0 & 0 & 1
    \end{bmatrix} \vec{v}.
  \end{align}
\end{mytheo}

\begin{proof}
  Vi visar först att (1) gäller innan vi går vidare. Låt $\vec{v}$ vara en vektor i $\mathbb{R}^3$. 
  Eftersom en rotation är en linjär transformation så gäller \hyperlink{linjarTsats}{sats 4.3.1} och 
  därför är
  \[Rot_{x\theta} (\vec{v}) = [\; Rot_{x\theta} (\vec{e}_1), Rot_{x\theta} (\vec{e}_2), 
  Rot_{x\theta} (\vec{e}_3)\;] \vec{v}\]
  där $\vec{e}_1, \vec{e}_2, \vec{e}_3 \in I_3.$
  Vi skall alltså analysera hur $\vec{e}_1 = 
  \begin{bmatrix}
    1 \\
    0 \\
    0
  \end{bmatrix}
  , \vec{e}_2 = 
  \begin{bmatrix}
    0 \\
    1 \\
    0
  \end{bmatrix}
  , \vec{e}_3 = 
  \begin{bmatrix}
    0 \\
    0\\
    1
  \end{bmatrix}
  $ förändras efter en rotaion med 
  $\theta$ kring $x-$axeln och till våran hjälp har vi figuren nedanför. 

  \newcommand{\AxisRotator}[1][rotate=0]{%
    \tikz [x=0.2cm,y=0.60cm,line width=.2ex,-stealth,#1] \draw (0,0) arc (-150:150:1 and 1);%
  }

  \begin{center}
    \begin{tikzpicture}
      \draw (0,0,0) --  (2,0,0)  node[pos=1.05]{$x$};
      \draw (0,0,0) -- (0,2,0) node[pos=1.05]{$y$};
      \draw (0,0,0) -- (0,0,2) node[pos=1.1]{$z$};
      \draw (0,0)  -- (1.8,0)  node [near end, scale=0.5] {\AxisRotator};
      
      \draw[thick, ->] (0,0,0) -- (1,0,0) node at (0.6, 0.3){$\vec{e_1}$};
      \draw[thick, ->] (0,0,0) -- (0,1,0) node at (-0.3, 0.6){$\vec{e_2}$};
      \draw[thick, ->] (0,0,0) -- (0,0,1) node at (-0.2, -0.6){$\vec{e_3}$};
      \node at (1, -0.3, 0) {1};
      \node at (0.3, 1, 0) {1};
      \node at (-0.3, 0, 1) {1};
    \end{tikzpicture}
  \end{center}
  $\vec{e}_1$ kommer att vara oförändrad efter en rotation kring $x-$axeln, 
  \[Rot_{x\theta}(\vec{e}_1) = 
  \begin{bmatrix}
    1 \\
    0 \\
    0
  \end{bmatrix}
  .\]
  Vi kollar närmare på hur $\vec{e}_1$ och $\vec{e}_2$ förändras efter en rotation. 
  \begin{center}
    \begin{tikzpicture}
      \draw (0,-2) -- (0,2) node[pos=1.05]{$y$};
      \draw (2,0) -- (-2,0)  node[pos=1.05]{$z$};

      \draw[thick, ->] (0,0) -- (-1,1) node at (-1.3, 1.3){$\vec{e}_2$};
      \draw[thick, dashed] (0,1) -- (-1,1);
      \draw[thick, dashed, white] (0,0) -- (0,1);
      \coordinate (a) at (0, 2);
      \coordinate (b) at (0, 0);
      \coordinate (c) at (-1, 1);
      \pic [draw, ->, "$\theta$", angle eccentricity=1.5] {angle = a--b--c};

      \draw[thick, ->] (0,0) -- (-1,-1) node at (-1.3, -1.3){$\vec{e}_3$};
      \draw[thick, dashed] (-1,0) -- (-1,-1);
      \draw[thick, dashed, white] (0,0) -- (-1,0);
      \coordinate (a) at (-2, 0);
      \coordinate (b) at (0, 0);
      \coordinate (c) at (-1, -1);
      \pic [draw, ->, "$\theta$", angle eccentricity=1.5] {angle = a--b--c};
    \end{tikzpicture}
  \end{center}
  $x-$komponanten för $\vec{e}_2$ och $\vec{e}_3$ är fortfarande noll eftersom de ligger på $y-$axeln. 
  Med enkel trigonometri så ser vi att $y-$komponanten för $\vec{e}_2$ är $\cos(\theta)$ och att 
  $z-$komponanten är $\sin(\theta)$ och därför är 
  \[Rot_{x\theta} (\vec{e}_2) = 
  \begin{bmatrix}
    0 \\
    \cos(\theta) \\
    \sin(\theta) 
  \end{bmatrix}.
  \] 
  Samma princip gäller för $\vec{e}_3$ och vi får att 
  \[Rot_{x\theta} (\vec{e}_3) = 
  \begin{bmatrix}
    0 \\
    -\sin(\theta) \\
    \cos(\theta)
  \end{bmatrix},
  \]
  vilket betyder att 
  \begin{align*}
    Rot_{x\theta} (\vec{v}) &= [\; Rot_{x\theta} (\vec{e}_1), Rot_{x\theta} (\vec{e}_2), 
    Rot_{x\theta} (\vec{e}_3)\;] \vec{v} \\
    &=
    \begin{bmatrix}
      1 & 0 & 0 \\
      0 & \cos(\theta) & -\sin(\theta) \\
      0 & \sin(\theta) & \cos(\theta)
    \end{bmatrix} \vec{v}.
  \end{align*}
  För 
  $Rot_{y\theta} (\vec{v})$ gäller det att 
  \[Rot_{y\theta} (\vec{v}) = [\; Rot_{y\theta} (\vec{e}_1), Rot_{y\theta} (\vec{e}_2), 
  Rot_{y\theta} (\vec{e}_3)\;] \vec{v}.\]
  $\vec{e}_2$ ligger på $y-$axeln och blir därför inte påverkad av en rotation.
  \[Rot_{y\theta} (\vec{e}_2) = 
  \begin{bmatrix}
    0 \\
    1 \\
    0
  \end{bmatrix}.
  \]
  Med trigonometri får vi även att 
  \[Rot_{y\theta} (\vec{e}_1) = 
  \begin{bmatrix}
    \cos(\theta) \\
    0 \\
    -\sin(\theta)
  \end{bmatrix}, \; Rot_{y\theta} (\vec{e}_3) = 
  \begin{bmatrix}
    \sin(\theta) \\
    0 \\
    \cos(\theta)
  \end{bmatrix}
  \]
  vilket betyder att 
  \[Rot_{y\theta} (\vec{v}) = 
  \begin{bmatrix}
    \cos(\theta) & 0 & \sin(\theta) \\
    0 & 1 & 0 \\
    -\sin(\theta) & 0 & \cos(\theta)
  \end{bmatrix} \vec{v}.\]
  För att visa att (3) gäller så använder man precis samma strategi. Denna del lämnas 
  som en övning till läsaren.
\end{proof}

\begin{exmp}
  Låt $\vec{v} = \begin{bmatrix}
    0 \\
    1 \\
    0
  \end{bmatrix}.$
  $Rot_{x \pi/2} (\vec{v})$ definieras då som
  \begin{align*}
    Rot_{x \pi/2} (\vec{v}) &= 
    \begin{bmatrix}
        1 & 0 & 0 \\
        0 & \cos(\frac{\pi}{2}) & -\sin(\frac{\pi}{2}) \\
        0 & \sin(\frac{\pi}{2}) & \cos(\frac{\pi}{2})
    \end{bmatrix}
    \begin{bmatrix}
      0 \\
      1 \\
      0
    \end{bmatrix} \\
    &= \begin{bmatrix}
      0 \\
      0 \\
      1
    \end{bmatrix}
  \end{align*}
  och roterar alltså $\vec{v}$ 90 grader moturs som bilden nedan illustrerar.
  %ta kanske bort denna bild, tar upp mycket plats?? Eller?????????
  \begin{center}
    \begin{tikzpicture}
      \draw (0,0,0) --  (2,0,0)  node[pos=1.05]{$x$};
      \draw (0,0,0) -- (0,2,0) node[pos=1.05]{$y$};
      \draw (0,0,0) -- (0,0,2) node[pos=1.1]{$z$};
      \draw [-latex, thick] (0, 0, 0) -- (0, 1, 0) node at (0.4, 1) {$\vec{v}$};
      \draw [-latex, thick] (0, 0, 0) -- (0, 0, 1) node at (0.7, -0.5) {$Rot_{x \pi/2} (\vec{v})$};
    \end{tikzpicture}
  \end{center}
\end{exmp}

\section{Gruppteori}
%---------------VIKTIGT------------------
%ändra introduktionen till gruppteori. Säg att addition kommer att användas occaisonaly 
%när det är nödvändigt men att vi kommer att diskutera det i djupet senare. 
Gruppteori är en väldig central del inom abstrakt algebra. 
Inom den abstrakta algebran så studerar man olika algebraiska strukturer
såsom grupper, ringar, kroppar och liknande strukturer och skiljer sig därmed från den elementära algebran. 

Man kan inom viss mån säga att den elementära algebran studerar de 
vanligaste talsystemen, $\mathbb{N}, \; \mathbb{Z}, \; \mathbb{Q}, \; \mathbb{R}, \; \mathbb{C}$,
och användingen av dessa.
Den elementära algebran är på så sätt 
extremt kraftfull. Det är exempelvis alltid användbart att kunna addera, subtrahera och 
ställa upp ekvationer 
med reella tal eftersom vi alltid kan dra parrallerer mellan dem
och den verkliga världen. Detta är också anledningen till varför den elementära algebran
studeras så mycket. 

Abstrakt algebra står lite på andra ändan av snörret när det gäller 
talsystem. Istället för att anaysera användningarna av de vanligaste talsystemen så 
ställs istället frågan om man kan hitta på nya och interesanta talsystem. Hela målet med detta är att försöka klämma ut vissa egenskaper hos de vanligaste 
talsystemen för att på så sätt generalisera det vi menar med ett användbart talsystem.

Det är möjligt att abstrahera bort praktiskt taget alla egenskaper hos ett talsystem för att skapa en struktur som kallas för en magma. Problemet med detta är att en
magma är alldeles för generell för att vara intresann. På samma sätt kan man abstrahera bort praktiskt taget inga egenskaper för att hitta
många resultat men som samtidigt blir alldeles för specifik för att lösa generella problem. Man vill alltså hitta en balans mellan dessa två extremfall och det man blir kvar med då är grupper och 
ringar. Ibland används även dessa extremfall ändå, till exempel så används monoider i datavetenskap vid användning av abstrakta datatyper. 

Denna text får tyvärr inte plats med alla dessa interesanta algebraiska strukturer. Del II tar dock upp mycket mer abstrakt algebra.
I denna text kommer vi alltså att ägna åt oss grundläggande gruppteori. 

Gruppteori är inte bara användbart för att generalisera vissa talsystem, utan används även som en abstrakt \textit{notation} för symmetri (vanligtvisst brukar man 
missförstå grupper och säga att de beskriver symmetrier av ett givet \textit{objekt}. Detta kallas dock för gruppverkan, vilket är ett sätt att tillämpa notationer för symmetri på ett givet objekt).
Detta gör att grupper blir tillämpliga i många olika områden, allt från relationer mellan polynom och dess röter (Galoisteori som tas upp i del II) och 
lösningarna av en Rubiks kub.

Innan vi börjar vår abstrakta grupp resa så kollar vi på följande talsystem
\[ \mathbb{Z} = \{0, 1, -1, 2, -2, \ldots\}. \]
Det som gör detta talsystem mycket mer än en tråkig mängd med symboler är att 
vi har ett sätt att \textit{sammansätta} två element. Man kan till exempel 
addera 1 med 2 för att få 3, ett annat heltal.
Vi inför nu en ny beteckning, $\circ$, för "sammansättning". Denna "sammansättning" kommer 
att fungera som en operation som man kan \textit{definiera hur man än vill}. Detta gör att vi inte behöver begränsa oss till endast addition för att generelisera grupper lite mer. 
Senare i texten kommer vi att dedikera denna symbol till en specifik operation för att underlätta saker och ting. 

Med detta ur vägen så kan vi nu definiera vad en grupp är. 

\hypertarget{def4.1}{}
\begin{mydef}{Grupp}{}
  En \textit{grupp} $G$ under operationen $\circ$, vilket skrivs $(G, \circ)$,
  är en mängd som uppfyller följande \textit{grupp axiom}.
  \begin{enumerate}[(i)] 
    \item \textbf{Slutenhet.} $x \circ y \in G$ för alla $x, y \in G$.
    \item \textbf{Assosiativitet.} $(x \circ y) \circ z = x \circ (y \circ z)$ för alla $x, y, z \in G$.
    \item \textbf{Enhetselementet.} Det existerar ett $e \in G$ så att $x \circ e = e \circ x = x$ för alla $x \in G$.
    \item \textbf{Inverser.} För alla $x \in G$ så existerar det ett $x^{-1} \in G$ så att $x \circ x^{-1} = x^{-1} \circ x = e$.
  \end{enumerate}
  Kardinaliteten av $G$ kallas för \textit{ordningen} och betecknades $|G|$.
\end{mydef}

\begin{exmp}
  Heltalen under addition, $(\mathbb{Z}, +)$, skapar en grupp eftersom grupp axiomen 
  \textbf{sluthet, assosiativitet, enhetselementet} och \textbf{inverser} uppfylls.

  \begin{enumerate}[(i)]
    \item \textbf{Slutenhet.} För alla heltal $x$ och $y$ så är alltid $x + y$ ett heltal. 
    \item \textbf{Assosiativitet.} För alla heltal $x, y, z$ så gäller $(x + y) + z = x + (y + z).$
    \item \textbf{Enhetselementet.} Enhetselementet är 0 eftersom $x + 0 = 0 + x = x,$ för alla heltal $x.$
    \item \textbf{Inverser.} Inversen för ett heltal $x$ är $-x$ eftersom $x + (-x) = (-x) + x = 0.$
  \end{enumerate}
\end{exmp}
Notera att grupp axiomen inte nämner något om kommutativitet. Det kan allså gälla att 
$x \circ y = y \circ x$ men detta är inte nödvändigt. För att särskilja sådana grupper från 
varandra så gör vi följande definition.
\begin{mydef}{Abelsk grupp}{}
  En \textit{abelsk grupp} $G$ är kommutativ, $x \circ y = y \circ x, \forall x, y \in G.$
\end{mydef}

\subsection{Konstruktion av en grupp}
För att konstruera en unik grupp så måste man först skapa en mängd av symboler och definiera 
en operation på elementen så att alla grupp axiom uppfylls.
Som man kanske kan gissa sig fram så blir detta svårt om vi vill skapa något nytt 
utan att använda de vanliga räknesätten. För att göra det enklare så görs följande definition.
\begin{mydef}{Permutation}{}
  En \textit{permutation} är en bijektion från en mängd till sig själv. En grupp innehållande 
  permutationer kallas för en \textit{permutationsgrupp}.
\end{mydef}
%definera vad en permutationsgrupp är här uppe.
Det blir betydligt mycket lättare att konstruera en unik grupp genom att använda permutationer. 
Man kan nämligen tänka sig att en grupp innehåller olika permutationer av en annan mängd. 

För att konstruera våran första grupp så skapar vi mängden $S = \{a, b\}.$
Alla möjliga permutationer av $S$ är 
\begin{center}
  \begin{tikzpicture}
    \draw (0,0) ellipse (0.5cm and 0.8cm);
    \node at (0, 0.4) {$a$};
    \node at (0, -0.4) {$b$};
    \draw (2,0) ellipse (0.5cm and 0.8cm);
    \node at (2, 0.4) {$a$};
    \node at (2, -0.4) {$b$};

    \draw[-latex] (0.2, 0.4) -- (1.8, 0.4);
    \draw[-latex] (0.2, -0.4) -- (1.8, -0.4);

    \draw (4.5,0) ellipse (0.5cm and 0.8cm);
    \node at (4.5, 0.4) {$a$};
    \node at (4.5, -0.4) {$b$};
    \draw (6.5,0) ellipse (0.5cm and 0.8cm);
    \node at (6.5, 0.4) {$a$};
    \node at (6.5, -0.4) {$b$};

    \draw[-latex] (4.7, 0.4) -- (6.3, -0.4);
    \draw[-latex] (4.7, -0.4) -- (6.3, 0.4);
  \end{tikzpicture}
\end{center}
Vi kan nu beteckna dessa permutationer beroende på hur elementen "byter plats". Permutationen
till vänster mappar $a$ till $a$ och $b$ till $b$ och agerar som ett enhetselement. En 
logisk beteckning för denna är därför $e$. Permutationen till höger mappar $a$ till $b$ och 
$b$ till $a$ och en vanlig beteckning för detta är $\tau.$ 
Med hjälp av Cauchy notationen så kan vi skriva dessa permutationer som 
\[e = 
\begin{pmatrix}
  a & b \\
  a & b
\end{pmatrix},
\tau = 
\begin{pmatrix}
  a & b \\
  b & a
\end{pmatrix}.
\]
Denna notation använder sig av en matris där den första raden anger elementen av en mängd 
och vad elementen blir mappade till i den andra raden.
Till exempel så är $\tau (a) = b, \; e(b) = b.$
Vi kan nu skapa en ny mängd
$G$ som innehåller dessa permutationer på följande sätt.
\[G = \{e, \tau\}.\]
Operationen $\circ$ kan nu definieras som den resulterande permutationen efter att ha 
tillämpat två permutationer efter varandra, $f \circ g = f(g), \; f, g \in G.$ Denna operation kallas för \textit{komposition} och används på många andra ställen i matematiken också.
Exempelvis så är $\tau \circ e = 
\tau (e)$ och genom att kolla på figuren nedan så kan vi dra slutsatsen att 
$\tau (e) = \tau$ och att $\tau (e(a)) = b.$ 

\begin{center}
  \begin{tikzpicture}
    \draw (0,0) ellipse (0.5cm and 0.8cm);
    \node at (0, 0.4) {$a$};
    \draw (0,0.4) ellipse (0.2cm and 0.2cm);
    \node at (0, -0.4) {$b$};
    \draw (2,0) ellipse (0.5cm and 0.8cm);
    \draw (2,0.4) ellipse (0.2cm and 0.2cm);
    \node at (2, 0.4) {$a$};
    \node at (2, -0.4) {$b$};

    \draw[-latex] (0.2, 0.4) -- (1.8, 0.4);
    \draw[-latex] (0.2, -0.4) -- (1.8, -0.4);

    % \draw[-latex] (2.2, 0.4) -- (4.3, 0.4);
    % \draw[-latex] (2.2, -0.4) -- (4.3, -0.4);

    % \draw (4.5,0) ellipse (0.5cm and 0.8cm);
    % \node at (4.5, 0.4) {$a$};
    % \draw (4.5,0.4) ellipse (0.2cm and 0.2cm);
    % \node at (4.5, -0.4) {$b$};
    \draw (4,0) ellipse (0.5cm and 0.8cm);
    \node at (4, 0.4) {$a$};
    \node at (4, -0.4) {$b$};
    \draw (4,-0.4) ellipse (0.2cm and 0.2cm);

    \draw[-latex] (2.2, 0.4) -- (3.8, -0.4);
    \draw[-latex] (2.2, -0.4) -- (3.8, 0.4);

    \draw [
    thick,
    decoration={
        brace,
        mirror,
        raise=0.5cm
    },
    decorate
] (0, -0.5) -- (1.9, -0.5) node [pos=0.5, yshift = -1cm] {$e$}; 

\draw [
  thick,
  decoration={
      brace,
      mirror,
      raise=0.5cm
  },
  decorate
] (2.1, -0.5) -- (4, -0.5) node [pos=0.5, yshift = -1cm] {$\tau$}; 
  \end{tikzpicture}
\end{center}

Notera att man först behöver utföra $e(a)$ innan $\tau (e(a))$.
På grund av detta 
så kommer $f \circ g, \; f, g \in G$ betyda att vi utför permutationen $g$ först 
och sedan $f$ och \textbf{inte} tvärtom. 

%skriv vad tabellen heter.
Vi kan nu skapa en tabell likt en multiplikations tabell som visar alla möjliga 
permutations sammansättningar av $G$. Detta kallas för en \textit{Cayles tabell} och kan användas för att definiera operationen $\circ$.

\begin{minipage}{\textwidth}
\centering
  \begin{tabular}{c | c c}
    $\circ$ & $e$ & $\tau$ \\
    \cline{1-3}
    $e$ & $e$  &$\tau$ \\
    $\tau$ & $\tau$  &$e$\\
  \end{tabular} 

  \medskip
  \footnotesize
  Tabell 1.
\end{minipage}

Elementen i $G$ är inte längre några tråkiga symboler utan något betydligt mer, nämligen permutationer. 
Vi har även ett sätt att sammansätta två permutationer, precis som man kan sammansätta två element
i $\mathbb{Z}.$ Dessutom så har permutationer en väldigt användbar egenskap som följande sats 
tar upp. 
\hypertarget{ass}{}
\begin{mytheo}{}{}
  Permutationer är associativa,
  \[(f \circ g) \circ h(x) = f \circ (g \circ h(x))\]
  för tre permutationer $f, g$ och $h$ från mängden $X$ till $X$ där $x \in X.$
\end{mytheo}
\begin{proof}
  Vänster ledet ger oss 
  \[V.L = (f \circ g) \circ h(x) = f(g(h(x)))\]
  och höger ledet ger 
  \[H.L = f \circ (g \circ h(x)) = f \circ g(h(x)) = f(g(h(x))).\]
  $V.L = H.L$ och beviset är slutfört.
\end{proof}

Det som återstår är att visa är att $G$ är en grupp. 
\begin{enumerate}[(i)]
  \item \textbf{Slutenhet.} Genom att kolla på Tabell 1 så ser vi att alla möjliga permutations
  sammansättningar. Alla dessa sammansättningar tillhör $G$ och därför uppfylls detta axiom.
  \item \textbf{Assosiativitet.} Detta axiom uppfylls enligt \hyperlink{ass}{sats 5q.1.1}
  \item \textbf{Enhetselementet.} Enhetselementet är 
  permutationen $e$ och därför uppfylls detta axiom
  \item \textbf{Inverser.} Elementen i $G$ är deras egna invers. $\tau \circ \tau = e$ och 
  $e \circ e = e$ vilket visas i Tabell 1. Detta axiom uppfylls.
\end{enumerate}
Alla grupp axiom uppfylls och därför är $G$ en permutationsgrupp. $G$ är även en abelsk grupp 
eftersom $x \circ y = y \circ x$ för $x, y \in G,$ vilket visas i Tabell 1.

Det har visat sig vara väldigt användbart att tänka på grupper som en mängd permutationer av en 
annan mängd. Dessutom så visar det sig att alla grupper kan "brytas" ned till permutationsgrupper
enligt Cayleys sats (som tas upp senare i texten).
Från och med nu, utan förlust av generalitet, kommer vi därför tänka på alla grupper framöver
som permutationsgrupper och om inget annat nämns så definieras $\circ$ på samma sätt som det 
gjordes här.

\subsection{Symmetriska grupper}
\begin{mydef}{Symmetriska grupper}{}
  Den \textit{symmetriska gruppen} $Sym(M)$ till en mängd $M$ består av alla möjliga permutationer
  av $M.$ Den symmetriska gruppen på $n$ element betecknas $S_n.$    
\end{mydef}
Vi har faktiskt redan gått igenom den symmetriska gruppen $S_2$ i förra avsnittet. 
Denna grupp betecknades dock $G$ istället för $S_2$ och mägden som permuterades var $S = \{a, b\}.$
Vi såg att $G = \{e, \tau\} = S_2$, där 
\[e = 
\begin{pmatrix}
  a & b \\
  a & b
\end{pmatrix},
\tau = 
\begin{pmatrix}
  a & b \\
  b & a
\end{pmatrix}.
\]
Eftersom $S_2$ redan har tagits upp och $S_1$ är trivial så kollar vi på $S_3$.
\hypertarget{exempel4.2}{}
\begin{exmp}
  Låt $M = \{1, 2, 3\}$, då är $Sym(M) = S_3$ eftersom $|M| = 3.$ Alla möjliga permutationer av 
  $M$ är 

  \begin{center}
    \begin{tikzpicture}
      \draw (0,0) ellipse (0.5cm and 0.8cm);
      \node at (0, 0.5) {1};
      \node at (0, 0) {2};
      \node at (0, -0.5) {3};
      \draw (1.6,0) ellipse (0.5cm and 0.8cm);
      \node at (1.6, 0.5) {1};
      \node at (1.6, 0) {2};
      \node at (1.6, -0.5) {3};

      \draw[-latex] (0.2, 0.5) -- (1.4, 0.5);
      \draw[-latex] (0.2, 0) -- (1.4, 0);
      \draw[-latex] (0.2, -0.5) -- (1.4, -0.5);

      \draw (3.6,0) ellipse (0.5cm and 0.8cm);
      \node at (3.6, 0.5) {1};
      \node at (3.6, 0) {2};
      \node at (3.6, -0.5) {3};
      \draw (5.2,0) ellipse (0.5cm and 0.8cm);
      \node at (5.2, 0.5) {1};
      \node at (5.2, 0) {2};
      \node at (5.2, -0.5) {3};

      \draw[-latex] (3.8, 0.5) -- (5, 0);
      \draw[-latex] (3.8, 0) -- (5, 0.5);
      \draw[-latex] (3.8, -0.5) -- (5, -0.5);

      \draw (7.2,0) ellipse (0.5cm and 0.8cm);
      \node at (7.2, 0.5) {1};
      \node at (7.2, 0) {2};
      \node at (7.2, -0.5) {3};
      \draw (8.8,0) ellipse (0.5cm and 0.8cm);
      \node at (8.8, 0.5) {1};
      \node at (8.8, 0) {2};
      \node at (8.8, -0.5) {3};

      \draw[-latex] (7.4, 0.5) -- (8.6, 0.5);
      \draw[-latex] (7.4, 0) -- (8.6, -0.5);
      \draw[-latex] (7.4, -0.5) -- (8.6, 0);

      \node at (0.8, -1) {$e$};
      \node at (4.4, -1) {$\tau_{12}$};
      \node at (8, -1) {$\tau_{23}$};

      \draw (0,-2) ellipse (0.5cm and 0.8cm);
      \node at (0, -1.5) {1};
      \node at (0, -2) {2};
      \node at (0, -2.5) {3};
      \draw (1.6,-2) ellipse (0.5cm and 0.8cm);
      \node at (1.6, -1.5) {1};
      \node at (1.6, -2) {2};
      \node at (1.6, -2.5) {3};

      \draw[-latex] (0.2, -1.5) -- (1.4, -2.5);
      \draw[-latex] (0.2, -2) -- (1.4, -2);
      \draw[-latex] (0.2, -2.5) -- (1.4, -1.5);

      \draw (3.6,-2) ellipse (0.5cm and 0.8cm);
      \node at (3.6, -1.5) {1};
      \node at (3.6, -2) {2};
      \node at (3.6, -2.5) {3};
      \draw (5.2,-2) ellipse (0.5cm and 0.8cm);
      \node at (5.2, -1.5) {1};
      \node at (5.2, -2) {2};
      \node at (5.2, -2.5) {3};

      \draw[-latex] (3.8, -1.5) -- (5, -2);
      \draw[-latex] (3.8, -2) -- (5, -2.5);
      \draw[-latex] (3.8, -2.5) -- (5, -1.5);

      \draw (7.2,-2) ellipse (0.5cm and 0.8cm);
      \node at (7.2, -1.5) {1};
      \node at (7.2, -2) {2};
      \node at (7.2, -2.5) {3};
      \draw (8.8,-2) ellipse (0.5cm and 0.8cm);
      \node at (8.8, -1.5) {1};
      \node at (8.8, -2) {2};
      \node at (8.8, -2.5) {3};

      \draw[-latex] (7.4, -1.5) -- (8.6, -2.5);
      \draw[-latex] (7.4, -2) -- (8.6, -1.5);
      \draw[-latex] (7.4, -2.5) -- (8.6, -2);

      \node at (0.8, -3) {$\tau_{13}$};
      \node at (4.4, -3) {$\sigma$};
      \node at (8, -3.1) {$\sigma \circ \sigma = \sigma^2$};
    \end{tikzpicture}
  \end{center}
  %kanske onöddigt att ha med detta nedan?
  Vi namnger dessa permutationer på liknande sätt som vi gjorde i förra avsnitt. Exempelvis så
  betyder $\tau_{13}$ att 1 mappas till 3 och vice versa medan allt annat mappas till sig självt.
  Lägg märke till att $\sigma^2 = \sigma \circ \sigma.$ Exponenten betyder alltså att man 
  \textbf{sammansätter} ett element $n$ gånger och \textbf{inte} multiplicerar, vilket 
  ibland kan vara vilseledande när symbolerna är heltal och $\circ$ definieras som addition.

  $Sym(M)$ är alla möjliga permutationer av $M$ och därför är 
  \[Sym(M) = S_3 = \{e, \tau_{12}, \tau_{23}, \tau_{13}, \sigma, \sigma^2\}.\]
  Även här kan man skapa en tabell likt Tabell 1 som gjordes i förra avsnittet. Vi hoppar 
  dock över detta. 

  Notera att $S_3$ inte är en abelsk grupp eftersom $\tau_{13} \circ \tau_{12} = \sigma$ medan
  $\tau_{12} \circ \tau_{13} = \sigma^2$ och att $|S_n|= n!$ 
  eftersom det första elementet kan mappas till 
  $n$ styckna element, det andra till $n-1$ element osv.
\end{exmp}
Vi kollar nu varför $S_n$ bildar en grupp.

% -----------------------------------
%-----------------VIKTIGT------------
% f
% https://www.math.kth.se/cirkel/2006/kompendium06.pdf
% LÄÄÄÄSSSSS
% -----------------------------------
%kanske gör en sats istället. Typ "sats 1.1: S_n är en grupp med operationen \circ. 
%Bevis \begin{enumerate} osv,...
\begin{enumerate}[(i)]
  \item \textbf{Slutenhet.} Låt $P = f \circ g, \; f, g \in S_n$. 
  Enligt \hyperlink{kompbij}{sats 3.3.1} så är $P$ en permutation
  och eftersom $S_n$ innehåller alla möjliga permutationer så måste $P \in S_n$ och därför 
  uppfylls detta axiom. %du måste visa att f \circ g är en permutation, det vill säga en bijektion.
  %https://www.math.kth.se/cirkel/2006/kompendium06.pdf LÄS DENNA
  \item \textbf{Assosiativitet.} Detta axiom uppfylls enligt \hyperlink{ass}{sats 5.1.1}.
  \item \textbf{Enhetselementet.} Eftersom $S_n$ innehåller alla möjliga permutationer 
  så måste det finnas en permutation $e$ som mappar alla element till säg själva och 
  därför uppfylls detta axiom. 
  \item \textbf{Inverser.} Eftersom varje bijektion har en invers, 
  som enligt \hyperlink{invbij}{sats 3.2.1} också är en bijektion, så måste 
  $S_n$ innehålla dessa inverser och därför uppfylls detta axiom.
\end{enumerate}

\subsection{Cykliska grupper}
I detta del avsnitt kommer vi att kolla på cykliska grupper.

\subsubsection{Ändliga cykliska grupper}
%ändra kanske definitionen så att det bara finns symboler???
\begin{mydef}{Cykliska grupper}{}
  En \textit{cyklisk grupp} av ordning $n$, som betecknas $C_n$, är en grupp där varje element 
  kan uttryckas som $g^c$ för $g \in C_n$ och $c \in \mathbb{Z}.$ Elementet $g$ kallas för 
  \textit{grupp generatorn}. Vi skriver 
  \[C_n = \langle g  \rangle \equiv \{g^n \; | \; n \in \mathbb{Z}\}.\]
  Ordningen för ett element $g$ är det \textit{minsta} heltalet $m$ så att $g^m = e$. 
\end{mydef}
Det enklaste sättet att skapa och förstå cykliska grupper är att tänka på en klocka. 
För att konstruera till exempel $C_{12}$ så kan man lägga 12 symboler, till exempel 
$1, 2, \ldots, 12$, runt en cirkel. $C_{12}$ kommer då vara mägden av alla permutationer 
som "roterar" alla element. Figuren nedan visar en lämplig permutation som tillhör $C_{12}.$

\begin{center}
  \begin{tikzpicture}[line cap=rect,line width=1.5pt, scale = 0.8]
    \draw (0,0) circle [radius=2cm];
    \foreach \angle [count=\xi] in {60,30,...,-270}
    {
      \node[font=\large] at (\angle:1.60cm) {$\xi$};
      \node[scale = 2] at (\angle + 100:2.4cm) {
        $\mathbin{\rotatebox[origin=c]{\angle}{\vstretch{1.5}{\curvearrowright}}}$}; 
    }
  \end{tikzpicture}
\end{center}
1 blir alltså mappad till 2, 2 till 3 osv. Vi betecknar denna permutation med $\sigma$,
precis som förut. Vi kan även "rotera" alla element två gångder, $\sigma^2$,
och totalt elva gånger, $\sigma^{11}$. Vi kan uppenbarligen inte rotera överhuvudtaget 
och på så sätt få enhetselementet, $\sigma^0 = e.$
Notera att $\sigma^{12} = e$ och att allt repeteras efter tolv rotationer. 
Det finns alltså ingen anledning till att rotera mer än tolv gånger.

Vi skapar nu en mängd innehållande alla dessa permutationer, 
\[C_{12} = \{e, \sigma, \sigma^2, \ldots, \sigma^{11}\}.\] 
Varje element i $C_{12}$ kan
uttryckas som $\sigma^n$ för ett heltal $n$ och därför är denna grupp cyklisk med grupp generatorn $\sigma$.

Notera nu att 
%kanske ta bort detta nedan. jag använder mig av addition för att förklara vad det är...
%vilket inte är det bästa man kan göra. 
\[\sigma^n \circ \sigma^m = 
\underbrace{\sigma \circ \sigma \circ, \ldots, \circ \sigma}_{\text{$n + m$}} = \sigma^{n+m}.\]
$\sigma$ och $\circ$ är ju bara symboler som vi har hittat på och vi kan ändra dem när som helst. 
Varför inte beteckna $\sigma^n$ som $n$? $\sigma^2$ blir alltså 2 och $\sigma$ blir 1. 
Det finns inte heller något som stoppar oss från att kalla $\circ$ för addition och beteckna den 
med $+$ istället. Med dessa nya beteckningar så blir
%ändra kanske detta nedan. Det känns jätte självklart och jag kanske borde om formulera mig. 
$C_{12} = \{0, 1, 2, 3, \ldots, 11\}$ 
och vi ser att
% --------------------------------------------
%---------------VIKTIGT-----------------------
% --------------------------------------------
%rita kanske en cirkel som först utför \sigma^2 och sedan \simga^1 och visa visuellt 
%att 1 + 2 = 3. Men detta blir dock bara visuellt medan det jag har nu är mer generellt...
%Vad fan ska jag göra??????
\[\sigma^1 \circ \sigma^2 = \sigma^3 \iff 1 + 2 = 3\]
och att 
\[\sigma^{11} \circ \sigma^1 = e \iff 11 + 1 = 0.\]
Det som är så tjusigt med cykliska grupper är att moduloräkning trillar ut helt naturligt. 
Vi har, genom att ha konstruerat en cyklisk grupp av ordning tolv, 
sätt att modulo tolv egentligen är en konsekvens av 
att ha permuterat tolv element runt en cirkel. Notera att detta kan generaliseras till 
modulo $n$ genom att skapa en cyklisk grupp av ordning $n$, talet tolv var helt slumpmässigt.

Vi kollar nu varför alla cykliska grupper uppfyller gruppaxiomen. För detta så antar vi 
att gruppen $G$ är cyklisk med grupp generatorn $g$.
\begin{enumerate}[(i)]
  \item \textbf{Slutenhet.} Eftersom $g$ är grupp generatorn så kan 
  $x, y \in G$ skrivas som $x = g^n, y = g^m$ för två heltal $n$ och $m$. 
  $g^n \circ g^m = g^{n + m}$ och eftersom 
  % g^n \circ g^m = g^c där c är kongruent med n + m modulo 12.
  $g$ är generatorn så måste $g^{n+m} \in G$. Notera att detta gäller även för $n+m > |G|$ eftersom 
  allt repeteras efter $g^{|G|}$ och därför uppfylls detta axiom.
  \item \textbf{Assosiativitet.} Detta axiom uppfylls enligt \hyperlink{ass}{sats 5.1.1}.
  \item \textbf{Enhetselementet.} Enhetselementet är permutationen som inte roterar något,
  $g^0.$
  \item \textbf{Inverser.} Inversen till $g^n$ för ett heltal $n$ är $g^{|G|-n}$ eftersom 
  $g^{n} \circ g^{|G|-n} = g^{|G|} = e$ och därför uppfylls detta axiom.
\end{enumerate}

\begin{exmp}
  Gruppen $S_2$ som med våra beteckningar definieras som $S_2 = \{e, \tau\}$ är 
  den cykliska gruppen $\mathbb{Z}_2$. Grupp generatorn är i detta fall 
  $\tau$ eftersom $\tau^2 = \tau \circ \tau = e$
  och genererar på så sätt hela gruppen.
\end{exmp}

%fundera och bevisa generellt på papper.
\begin{exmp}
  Mängden av de reella och komplexa lösningarna, som visas i figuren nedan,
  till ekvationen $z^5 = 1$ bildar en cyklisk grupp under operationen multiplikation.
  
  \begin{center}
    \begin{tikzpicture}
      \draw[-latex] (-2, 0) -- (2, 0) node[below] {$Re$};
      \draw[-latex] (0, -2) -- (0, 2) node[right] {$Im$};
      
      \draw[fill] (1, 0) circle [radius=1pt];
      \draw[fill] (0.309, 0.9510565) circle [radius=1pt];
      \draw[fill] (-0.809, 0.5877852) circle [radius=1pt];
      \draw[fill] (-0.809, -0.5877852) circle [radius=1pt];
      \draw[fill] (0.309, -0.9510) circle [radius=1pt];

      \draw[blue] (0.309, 0.9510565) -- (-0.809, 0.5877852);
      \draw[blue] (-0.809, 0.5877852) -- (-0.809, -0.5877852);
      \draw[blue] (-0.809, 0.5877852) -- (-0.809, -0.5877852);
      \draw[blue] (-0.809, -0.5877852) -- (0.309, -0.9510);
      \draw[blue] (1, 0) -- (0.309, 0.9510565);
      \draw[blue] (1, 0) -- (.309, -0.9510);
    \end{tikzpicture}
  \end{center}
  Mängden av lösningarna till $z^5 = 1$ är
  \[ L = \left\{ 
  1, \; 
  \pm \left( \cos \left( \frac{2 \pi}{5} \right) + i \sin \left( \frac{2 \pi}{5} \right) \right), \;
  \pm \left( \cos \left( \frac{4 \pi}{5} \right) + i \sin \left( \frac{4 \pi}{5} \right) \right)
  \right\} \]
  vilket enkelt kan visas genom att använda de Moivres formel. Vi ser att
  $z_2 = 
  \pm \left( \cos \left( \frac{2 \pi}{5} \right) + i \sin \left( \frac{2 \pi}{5} \right) \right)$
  genererar hela grupper eftersom $L = \{ z_2^0, z_2^1, z_2^2 \}$. $(L, \cdot)$ är cyklisk 
  %skriv om detta.
  och därmed också en grupp. Detta gäller för alla lösningar till ekvationen 
  på typen $z^n = 1$ under operationen multiplikation
  och en bra övning är att bevisa detta. 
\end{exmp}

\subsubsection{Oändliga cykliska grupper}
Skillnaden mellan ändliga cykliska grupper och oändliga cykliska grupper är 
hur många element som permuteras. 
När vi kollade på ändliga grupper så roterade vi ändligt många element. 
Med ändligt många element så finns det alltid ett sista element
som kan bli mappad till något, 
vilket gjorde att alla element slutligen roterar ett helt varv
efter repeterande permutatiner.
Tack vare detta så behöver man inte ha några direkta inverser som roterar elementen 
åt andra hållet. 

Vid fallet med oändliga cykliska grupper så finns det inget sista element. 
Tillföljd av detta så är det nödvändigt 
med direkta inverser som roterar åt motsatt håll för att alla gruppaxiom skall uppfyllas. 
På grund av detta faktum så blir det lite vilseledande om vi fortsätter rita cirklar. 
Vi ritar därför två tallinjer på varandra istället där den översta innehåller symbolerna 
som skall permuteras och där den
nedersta visar vart alla element mappas till 
efter en rotation.

\begin{center}
  \begin{tikzpicture}
    \draw[latex-latex] (-4,0) -- (4,0);
    \foreach \x in  {-3,-2,...,3}
    {
      \draw (\x,0.1) -- (\x,-0.1);
      \node at (\x, -0.4) {$\x$};
      \draw[-latex, red] (\x, -0.6) -- (\x + 1, -1.8);
      \draw[-latex, blue] (\x, -0.6) -- (\x - 1, -1.8);
    }

    \draw[latex-latex] (-4,-2) -- (4,-2);
    \foreach \x in  {-3,-2,...,3}
    {
      \draw (\x,-2.1) -- (\x,-1.9);
      \node at (\x, -2.4) {$\x$};
    }

    \node at (-3.5, -0.4) {$\cdots$}; 
    \node at (3.5, -0.4) {$\cdots$}; 
    \node at (3.5, -2.4) {$\cdots$}; 
    \node at (-3.5, -2.4) {$\cdots$}; 
  \end{tikzpicture}
\end{center}
De röda pilarna i figuren ovan visar permutationen $\sigma$ och de blåa visar $\sigma^{-1}$.
Vi kan givetvis rotera flera gånger och, som tidigare nämnts, så är vi inte begränsade
till hur många gånger vi roterar. 
Den oändliga cykliska gruppen, som vi i denna text kommer att beteckna med $C$, är per definition 
\[C = \{ \sigma^n \; | \; n \in \mathbb{Z} \} = 
\{ \sigma, \sigma^{-1}, \sigma^2, \sigma^{-2}, \ldots \}.\]
Precis som förut så kan vi ändra våra beteckningar till något mer passande. 
Vad sägs om att beteckna $\sigma^n$ med $n$ och $\circ$ med $+$? 
Det är redan uppenbart från tidigare avsnitt att 
\[\sigma^5 \circ \sigma^3 = \sigma^8\]
och med våra nya beteckningar så kan följande ekvivalenta formulering ställas upp
\[5 + 3 = 8\]
vilket naturligtvist gäller inom den elementära algebran. 
Hela syftet som försöks framföras är att gruppteorin ger en alternativ synpunkt till vad 
tal egentligen är. Tal är i detta fall 
inte några tråkiga symboler och inte heller ett mått på hur många 
saker man har, utan istället permutationer. Addition, +, definierade vi som komposition, $\circ$,
och komposition som den resulterande permutationen efter att ha tillämpat två permutationer 
efter varandra. Men man kan ju definiera $\circ$ precis som man önskar! 
Gruppen av heltal under operationen +, som alla använder dagligen, är alltså endast 
en infinitesimal skiva av det som finns att utforska inom gruppteorin. 

Notera dock att detta sätt att \textit{se} tal på är ifrån ett gruppteoretiskt perspektiv. 
Vi har egentligen inte definierat heltalen samt addition och om man vill ha formella och strikta definitioner så kan man läsa igenom \textit{Peanos axiom} som 
innehåller många axiom för de naturliga talen. 
Peanos axiom har varit väldigt viktig 
för forskning inom konsistens och fullständighet inom talteorin och kommer att betjäna 
de intresserade läsarna som söker efter mer rigorösa definitioner.

%ta kanske upp varför oändliga cykliska grupper uppfyller grupopaxiomen. Kanskde inte 
%nödvändigt tho. 

\subsection{Dihedrala grupper}
\textit{Dihedrala grupper} kan sägas vara en utvidgning av konceptet om cykliska grupper. En cyklisk grupp kan sägas rotera 
en geometrisk figur (vi säger att den cykliska gruppen $C_n$ \textit{verkar} på hörnen av en $n$-hörning. Detta förklaras senare). Men förstås 
så kan vi göra mer med en geometrisk figur än att bara rotera den, vi kan spegla den också. Om vi betraktar triangeln nedanför så kan 
vi utföra totalt sex styckna rotationer och speglingar. 

\begin{center}
  \begin{tikzpicture}
    \node[regular polygon,regular polygon sides=3, draw, rotate=0, scale=3] at (0,0){} node at (0, 0) {$\uparrow$};
    \node[] at (0, -0.7){$e$};
    \node[regular polygon,regular polygon sides=3, draw, rotate=120,scale=3] at (4,0) {} node[rotate=120] at(4,0){$\uparrow$};
    \node[] at (4, -0.7){$\sigma^2$};
    \node[regular polygon,regular polygon sides=3, draw, rotate=240,scale=3] at (2,0) {} node[rotate=240] at (2,0) {$\uparrow$};
    \node[] at (2, -0.7){$\sigma$};

    \node[regular polygon,regular polygon sides=3, draw, rotate=0, scale=3] at (0,-2){};
    \draw[dashed] (0, -1) -- (0, -2.5);
    % \draw[dashed, shift={(1, 0)}, rotate=120] (0, -1) -- (0, -2.5);
    \draw[dashed, shift={(4, -2)}, rotate=120] (0, 1) -- (0, -0.5);
    \draw[dashed, shift={(2, -2)}, rotate=240] (0, 1) -- (0, -0.5);

    \node[regular polygon,regular polygon sides=3, draw, rotate=0, scale=3] at (2,-2){};
    \node[regular polygon,regular polygon sides=3, draw, rotate=0, scale=3] at (4,-2){};

    \node[] at (0, -2.7){$\tau$};
    \node[] at (2, -2.7){$\tau \circ \sigma$};
    \node[] at (4, -2.7){$\tau \circ \sigma^2$};
    % \draw[help lines](-5,5) grid (5,-6); 
  \end{tikzpicture}
\end{center}
Den dihedrala gruppen av ordning 6 är alltså $D_6 = \{e, r, r^2, \tau, \tau \circ \sigma, \tau \circ \sigma^2\}$.
En egenskap som de dihedrala grupperna har är att $\tau^{-1} \circ \sigma \circ \tau = \sigma^{-1}$. Detta kan man illusterara 
genom att skapa en triangel av papper, markera alla hörn med tal och först utföra en spegling av triangeln, en rotation och tillslut en till spegling. 
Då borde triangeln hörn vara placerade på ett sådant sätt som motsvarar en omvänd rotation. Detta "experiment" visar dock endast att
$D_6$ har denna egenskap. Vi får helt enkelt köpa faktumet att detta gäller för alla $D_n$. Vi kan definiera dihedrala grupper lite mer 
formellt. 

\begin{mydef}{}{}
  Den \textit{dihedrala gruppen av ordning} $2n$ är 
  \[D_{2n} = \langle \sigma, \tau \; | \; \sigma^n = e, \; \tau^2 = e, \; \tau^{-1} \circ \sigma \circ \tau = \sigma^{-1} \rangle  \]
\end{mydef}
\subsection{Delgrupper}
\begin{mydef}{Delgrupper}{}
  En \textit{delgrupp} $H$ av gruppen $G$ är en delmängd av $G$ som också är en grupp och vi 
  skriver $H \le G$. Om $H \le G$ och $H \neq G$ så är $H$ en \textit{äkta delgrupp} av $G$
  och vi skriver $H < G$.
\end{mydef}
Lägg märkte till att varenda grupp $G$ har minst två delgrupper, den triviala delgruppen 
$\{e\} = S_1$ och $G$.
\begin{exmp}
  Den cykliska gruppen av ordning tre är en delgrupp av den symmetriska gruppen på tre element
  under operationen komposition $\circ$,
  $C_3 < S_3$. Detta eftersom $C_3 \subset S_3$ och $C_3$ bildar en grupp 
  under operationen $\circ$ enligt tidiare resultat.
  %"bildar en grupp enligt tidiare resultat" ändra detta till någon sats om jag ska ändra runt allt.
  %"enligt sats..."
\end{exmp}
\begin{exmp}
  $c \mathbb{Z} = \{cz \; | \; z \in \mathbb{Z}\} \le \mathbb{Z}$ (där $cz$ betyder 
  att vi multiplicerar $c$ med $z$) för ett heltal $c$ under operationen 
  addition. 
  Detta eftersom $c \mathbb{Z} \subseteq \mathbb{Z}$ och $c \mathbb{Z}$ bildar en 
  grupp under addition, vilket läsaren får lov att visa.
\end{exmp}
%nedan kan vara fristående appendix.
Det visar sig faktiskt att alla delgrupper till gruppen $(\mathbb{Z}, +)$ 
är på formen $c \mathbb{Z}$, vilket vi nu skall visa. 
\begin{mytheo}{}{}
  Alla delgrupper till gruppen $(\mathbb{Z}, +)$ 
  är på formen $c \mathbb{Z}, c \in \mathbb{Z}$.
\end{mytheo}
\begin{proof}
  Låt $H \le \mathbb{Z}$ under operationen addition. 
  Eftersom $H$ är en delgrupp till $\mathbb{Z}$ så gäller, per definition, att 
  $H \subseteq \mathbb{Z}$ och att $(H, +)$ bildar en grupp. 
  Eftersom $H$ är en delmängd av $\mathbb{Z}$ så finns det två olika fall för $H$.
  \begin{enumerate}[(i)]
    \item $H$ kan vara den triviala delgruppen, det vill säga $H = \{0\}$. 
    \item $H$ är inte den triviala delgruppen.
  \end{enumerate}
  Om I) gäller så är $H = 0 \mathbb{Z}$ och alltså på formen $c \mathbb{Z}$ och beviset är 
  slutfört.
  
  Om II) gäller så måste $H$ innehålla både positiva och negativa heltal för att 
  gruppaxiomet "Inverser" skall uppfyllas. Detta medför att det måste finnas 
  ett minsta positiva heltal i $H$, vilket vi kan kalla för $b$.
  Vi visar nu att $H = b \mathbb{Z}$, 
  vilket är ekvivalent med att visa att $H \subseteq b \mathbb{Z}$
  och att $b \mathbb{Z} \subseteq H.$

  Vi visar först att $b \mathbb{Z} \subseteq H.$   
  Eftersom $H$ är en grupp och $b \in H$ så måste 
  även $nb \in H$ för ett naturligt tal $n$ enligt gruppaxiomet "Slutenhet". 
  Vidare har vi även att $-nb \in H$ enligt gruppaxiomet "Inverser".
  Eftersom 
  $b \mathbb{Z} = \{bz \; | \; z \in \mathbb{Z}\}$ så gäller $b \mathbb{Z} \subseteq H.$

  Det som återstår att visa är att $H \subseteq b \mathbb{Z}$. Vi antar motsatsen, 
  $H \not\subseteq b \mathbb{Z}$. Detta betyder att det existerar ett 
  $a \in H$ så att $a \notin b\mathbb{Z}.$ Eftersom $a \notin b\mathbb{Z}$ så 
  kan $a$ skrivas som $zb + r$ för $b > r > 0$, vilket betyder 
  att $r = a + (-zb)$. $a \in H$ och eftersom $-zb \in b \mathbb{Z}$ och $b \mathbb{Z} \subseteq H$ 
  så måste
  $-zb \in H$, vilket medför att $r \in H$ enligt gruppaxiomet "Sluthet". Villkoret $b > r > 0$ ger oss att $r$ är mindre än $b$, vilket är en motsägelse och därför 
  måste $H \subseteq b \mathbb{Z}$.
  
  Eftersom $H \subseteq b \mathbb{Z}$ samtidigt som $b \mathbb{Z} \subseteq H$ så måste 
  $b \mathbb{Z} = H$ och $H$ är alltså på den önskade formen.
\end{proof}



%skriv kanske inte något på dihedrala grupper, onödigt...

%------------------VIKTIGT---------------------------
%ändra "mappas" eller "map" och använd avbildning istället
\subsection{Grupp Homomorfism}
\begin{mydef}{Grupp Homomorfism}{}
  Låt $(G, \circ)$ och $(G', \cdot)$ vara grupper. 
  En \textit{grupp homomorfism} är en funktion $\varphi$ från $G$ till $G'$ som 
  uppfyller följande villkor
  \[\varphi (x \circ y) = \varphi (x) \cdot \varphi (y) \; \forall x, y \in G.\]
\end{mydef}

\begin{center}{}
    \begin{tabular}{c | c c c}
      $\circ$ &  & $y$ &\\
      \cline{1-4}
      &  &  & \\
      $x$ &  & $x \circ y$ & \\
      &  &  & \\
    \end{tabular} 
    \quad
    \begin{tikzpicture}
      % \node[font=\large] at (0.5, -0.2) {$\varphi : G \rightarrow G'$};
      \draw[-latex] (0, -1) -- (1.5, -1) node[font=\large] at (0.75, -0.7) {$\varphi$};
    \end{tikzpicture}
    \quad
    \begin{tabular}{c | c c c}
      $\cdot$ &  & $\varphi(y)$ &\\
      \cline{1-4}
      &  &  & \\
      $\varphi(x)$ &  & $\varphi(x) \cdot \varphi(y)$ & \\
      &  &  & \\
    \end{tabular} 
\end{center}
%kanske ändra definitionen eller ändra detta nedan. Jag måste föklara bättre.
Figuren ovan illusterar en homomorfism mellan två grupper som representeras av tabeller.
Homomorfism är alltså ett sätt att jämföra två gruppers algebraiska struktur. Notera även att 
varje linjär transformation är en homomorfism mellan två vektorrum.

\hypertarget{exmp4.7}{}
\begin{exmp}
  Låt $G$ vara gruppen av de reella talen under addition och $G'$ vara gruppen av de reella 
  talen under multiplikation. $\varphi$ från $G$ till $G'$ som definieras 
  av $\varphi(x) = e^x$ är då en homomorfism eftersom
  \[\varphi(x + y) = e^{x+y} = e^x \cdot e^y = \varphi(x) \cdot \varphi(y).\]
\end{exmp}

\begin{mytheo}{}{}
  Låt $(G, \circ)$ och $(G', \cdot)$ vara grupper och 
  $\varphi: G \rightarrow G'$ en homomorfism. Då gäller 
  \begin{enumerate}[(i)]
    \item $\varphi(e_G) = e_{G'}$ där $e_G$ är enhetselementet i $G$ och $e_{G'}$ är
    enhetselementet i $G'$.
    \item $(\varphi(x))^{-1} = \varphi(x^{-1}) \ \forall x \in G.$
  \end{enumerate}
\end{mytheo}
\begin{proof}
  I). Eftersom $\varphi$ är en homomorfism så gäller 
  \begin{align*}
    \varphi (e_G \circ y) &= \varphi (e_G) \cdot \varphi (y) \iff \\
    \varphi (y) &= \varphi (e_G) \cdot \varphi (y)
  \end{align*}
  för $y \in G.$ I högerledet komponerar vi $\varphi (e_G)$ med $\varphi (y)$ för att få tillbaka 
  $\varphi (y)$. $\varphi (e_G)$ agerar alltså som enhetselementet och därför måste 
  $\varphi (e_G) = e_{G'}.$

  II). Notera först att $(\varphi(x))^{-1}$ är inversen till $\varphi(x)$. 
  Eftersom $\varphi$ är en homomorfism så gäller
  \begin{align*}
    \varphi (x \circ x^{-1}) &= \varphi (x) \cdot \varphi (x^{-1}) \iff \\
    \varphi (e_G) &= \varphi (x) \cdot \varphi (x^{-1})
  \end{align*}
  och enligt I) får vi
  \[e_{G'} =\varphi (x) \cdot \varphi (x^{-1}).\]
  för $x \in G.$
  $\varphi (x^{-1})$ och $(\varphi(x))^{-1}$ är alltså båda inverser till $\varphi (x)$
  och eftersom det endast existerar en invers för varje element i en grupp så måste 
  $\varphi (x^{-1}) = (\varphi(x))^{-1}.$
\end{proof}

\begin{mydef}{Kärnan och bilden av en homomorfism}{}
  Låt $G$ och $G'$ vara grupper och $\varphi : G \rightarrow G'$ en homomorfism.
  \textit{Kärnan} av $\varphi$ betecknas $ker(\varphi)$
  och ges av 
  \[ker(\varphi) \equiv \{g \in G \; | \; \varphi(g) = e_{G'}\}.\]
  \textit{Bilden} av $\varphi$ betecknas med $Im(\varphi)$ och ges av 
  \[Im(\varphi) \equiv \{\varphi(g) \; | \; g \in G\}.\]
  På engelska kallas kärnar för \textit{kernel} och bilden för \textit{image}, varifrån 
  förkortningarna härstammar.
\end{mydef}
Kärnan av en homomorfism är alltså alla element i definitionsmängden som blir mappade 
till enhetselementet i målmångden och bilden av en homomorfism är värdemängden. 
Figuren nedan visar vad alla dessa nya begrepp betyder visuellt.
\begin{center}
  \begin{tikzpicture}
    \begin{scope} [fill opacity = .3]
      \draw[fill = blue] (-2.5,0) ellipse (2 and 2.5);
      \draw[fill = myblue] (2.5,0) circle (2);
      \draw[fill = blue] (2,0) ellipse (1 and 1.5) node[opacity=1] at (2, 0.5) {$Im(\varphi)$}
      node[opacity = 1] at (2, -0.5) {$e$} node[opacity = 1, scale=2] at (1.8, -0.5) {$.$};
      \draw[fill = red] (-2,-0.5) ellipse (1 and 1.2) node[opacity = 1, scale=2] at (-2, -0.5) {$.$}
      node[opacity = 1] at (-1.8, -0.5) {$e$} node[opacity = 1] at (-2, 0) {$ker(\varphi)$};
    \end{scope}

    \draw[thick] (-2.5, 2.5) -- (2, 1.5);
    \draw[thick] (-2.5, -2.5) -- (2, -1.5);

    \draw[thick] (-2, 0.7) -- (1.8, -0.5);
    \draw[thick] (-2, -1.7) -- (1.8, -0.5);
    % \draw[help lines](-5,5) grid (5,-6); 

    \node[scale = 1.6] at (-2.5, -3) {$G$};
    \node[scale = 1.6] at (2.5, -3) {$G'$};
    \draw[-latex, thick] (-2, -3) -- (2, -3) node[scale = 1.6] at (0, -2.5) {$\varphi$};
  \end{tikzpicture}
\end{center}

Det visar sig nämligen att för en homomorfism $\varphi : G \rightarrow G'$ så gäller
$Im(\varphi) \le G'$ och $ker(\varphi) \le G$. Eftersom det redan är uppenbart att
$Im(\varphi) \subseteq G'$
%kanske bevisa detta nedan ändå, eller??
och att $ker(\varphi) \subseteq G$ så behöver man alltså bara visa att kärnan och bilden bildar 
grupper. Detta utelämnas dock i denna text och läsaren får gärna visa detta på egen hand.

Det som är viktigt med detta resultat är att vi kan tänka på alla injektiva homomorfier som
surjektiva också genom att begränsa målmängden till endast bilden. Säg till exempel att 
$\varphi : G \rightarrow G'$ är en injektiv homomorfism. För att göra $\varphi$ surjektiv och injektiv 
så kan man ändra målmängden till $Im(\varphi)$ så att $\varphi : G \rightarrow Im(\varphi)$.
Helt visuellt så betyder detta att vi tar bort det gula området 
(som innehåller alla element som inte är mappade till något i definitionsmängden) i figuren ovan.


\subsubsection{Grupp isomorfism}
\begin{mydef}{Isomorfism}{}
  En \textit{grupp isomorfism} är en grupp homomorfism som är bijektiv. 
  Om två grupper, $G$ och $G'$, är 
  isomorfa skriver vi $G \cong G'$.
\end{mydef}
Notera att varje isomorfism är en homomorfism men att
varje homomorfism inte behöver vara en isomorfism. 
Eftersom en isomorfism är en bijektion så är två gruppers algebraiska struktur identiska 
om de är isomorfa. Detta betyder att två isomorfa grupper endast skiljer sig åt symbol mässigt. 
Man kan alltså ändra sina symboler i den ena gruppen för att få den andra, vilket är den informella 
definitionen av isomorfism.


\begin{exmp}
Tidigare i texten har vi sätt att vi kan få gruppen av heltal under addition genom att 
ändra våra beteckningar i den oändliga cykliska gruppen. Detta betyder att 
den oändliga cykliska gruppen under komposition och heltalen under addition är isomorfa.
Mer formellt så är $C \cong \mathbb{Z}$ eftersom homomorfismem
$\varphi: C \rightarrow \mathbb{Z}$ 
som definieras av 
$\varphi (\sigma^n) = n$
är en bijektion.
\end{exmp}

\begin{exmp}
  I \hyperlink{exmp4.7}{exempel 5.7} hade vi den injektiva homomorfismem 
  $\varphi : (\mathbb{R}, +) \rightarrow (\mathbb{R}, \cdot)$ som definierades av 
  $\varphi(x) = e^x.$ För att göra $\varphi$ bijektiv, och på så sätt göra den till en isomorfism, 
  så kan 
  vi ändra målmängden, $\mathbb{R}$, till bilden, $Im(\varphi)$. Eftersom $e^x, x \in \mathbb{R}$
  alltid är positiv så är $Im(\varphi)$ alla positiva reella tal, $\mathbb{R}^+.$
  Genom att begränsa målmängden till bilden så tar vi bort alla element som inte blir 
  mappade till något i definitionsmängden och därför är 
  $\varphi : (\mathbb{R}, +) \rightarrow (\mathbb{R}^+, \cdot)$ en isomorfism. 
\end{exmp}

\subsection{Cayleys sats}
Vi har redan sätt att vi kan konstruera en grupp busenkelt genom att använda permutationer
och majoriteten av alla grupper som har tagits upp har varit permutationsgrupper. Men 
\hyperlink{def4.1}{definitionen} nämner dock inget om permutationer och därför 
kan det kännas som vi endast har kollat på ett specialfall av grupper. Det är precis nu 
Cayles sats, som påstår att varje grupp kan tänkas som en permutationsgrupp, kommer till hands. 
Eftersom varje grupp kan tänkas som en permutationsgrupp så kan vi alltså endast kolla 
på permutationsgrupper utan att förlora generalitet.

För att bevisa denna viktiga sats så observerar vi följande.
\begin{enumerate}
  \item Alla delgrupper till $S_n$ är permutationsgrupper eftersom $S_n$ 
  innehåller alla möjliga permutationer på $n$ element.
  \item När vi säger att varje grupp kan "tänkas" som en permutationsgrupp så menar vi egentligen att varje grupp är isomorfisk med en permutationsgrupp. 
\end{enumerate}
Med hjälp av 1 och 2 kan vi omformulera Cayles sats så att den blir lättare att bevisa. 
\begin{mytheo}{Cayleys sats}{}
  Varje grupp $G$ är isomorfisk med en delgrupp av $Sym(G)$.
\end{mytheo}
\begin{proof}
  Definiera gruppen $(G, \cdot)$ och låt $\lambda_x: G \rightarrow G$ vara en funktion som 
  definieras av $\lambda_x (g) = x \cdot g$ för $x, g \in G$. 
  $\lambda_x$ är injektiv eftersom $\forall a, b \in G, \lambda_x(a) = \lambda_x (b) \implies
  x \cdot a = x \cdot b \implies x^{-1} \cdot x \cdot a = x^{-1} \cdot x \cdot b \implies a = b.$
  Dessutom är $\lambda_x$ surjektiv eftersom vi alltid kan hitta ett $b \in G$ så att 
  $a = \lambda_x(b)$ för alla $a \in G$, nämligen $b = x^{-1} \cdot a.$
  $\lambda_x$ är alltså en bijektion och eftersom $\lambda_x$ går från $G$ till $G$ så är 
  den, per definition, en permutation av $G$ och måste därför vara ett element i $Sym(G)$. 

  Definiera mängden $H = \{\lambda_x \; |\; x \in G\; \}$ under operationen komposition, $\circ$.
  Härnäst visar vi att $H$ är en grupp.
  \begin{enumerate}[(i)]
    \item \textbf{Slutenhet.} Låt $x, y, g \in G$, då gäller
    $(\lambda_x \circ \lambda_y)(g) = \lambda_x(\lambda_y(g)) = x \cdot y \cdot g = 
    \lambda_{x \cdot y}(g).$ Eftersom $G$ är en grupp så är $x \cdot y \in G$ vilket medför 
    att $\lambda_{x \cdot y} = \lambda_x \circ \lambda_y \in H$ och axiomet uppfylls.
    \item \textbf{Assosiativitet.} Detta axiom uppfylls enligt \hyperlink{ass}{sats 5.1.1}
    \item \textbf{Enhetselementet.} Enhetselementet är $\lambda_{e_G}$ där $e_G$ är 
    enhetselementet i $G$ och därför 
    uppfylls detta axiom. Detta eftersom $(\lambda_x \circ \lambda_{e_G})(g) = x \cdot e_G \cdot g
    = x \cdot g = \lambda_x (g)$ för $x, g \in G.$
    \item \textbf{Inverser.} Inversen till $\lambda_x$ är $\lambda_{x^{-1}}$ för $x \in G$
    och därför uppfylls detta axiom. 
    Detta eftersom, för $x, g \in G$, $(\lambda_x \circ \lambda_{x^{-1}})(g) = x \cdot x^{-1} \cdot g = 
    e_G \cdot g = \lambda_{e_G} (g)$ vilket är enhetselementet enligt III.
  \end{enumerate}
  Det är uppenbart att $H \subseteq Sym(G)$ och eftersom $H$ är en grupp så är $H$ en delgrupp 
  till $Sym(G)$. 

  Vi visar nu att $G \cong H$ för att slutföra beviset. Låt $\varphi: G \rightarrow H$ 
  vara en funktion definierad av $\varphi(x) = \lambda_x$. Notera att $\varphi$ direkt 
  blir surjektiv tillföljd av dess kontruktion och eftersom 
  $\forall x, y \in G, \varphi(x) = \varphi(y) \implies \lambda_x (g) = \lambda_y (g)
  \implies x \cdot g = y \cdot g \implies x = y$ för $g \in G$ så är även $\varphi$ injektiv. 
  Det som återstår att visa är att $\varphi$ är en homomorfism. För 
  $x, y \in G$ gäller $\varphi(x \cdot y) = \lambda_{x \cdot y}$. 
  Notera att $\lambda_{x \cdot y} (g) = x \cdot y \cdot g = (\lambda_x \circ \lambda_y)(g)$ 
  vilket betyder att $\varphi(x \cdot y) = \lambda_x \circ \lambda_y = \varphi(x) \circ \varphi(y)$
  och $\varphi$ är alltså en bijektiv homomorfism, det vill säga en isomorfism.
\end{proof}

\subsection{Sidoklasser och Lagranges sats}
\begin{mydef}{}{Sidoklasser}
  Låt $(H, \circ)$ vara en delgrupp till $(G, \circ)$ och $a$ vara ett element i $G$. 
  Då är
  \[a \circ H \equiv \{a \circ h \; | \; h \in H\}\]
  en \textit{vänstersidoklass} till $H$ med avseende på $a$ och 
  \[H \circ a \equiv \{h \circ a \; | \; h \in H\}\]
  en \textit{högersidoklass} till $H$ med avseende på $a$. Ibland brukar $\circ$ utelämnas 
  och då skrivs $aH$ respektive $Ha$ istället.
\end{mydef}
\begin{exmp}
  Betrakta gruppen av heltal under addition och delgruppen $H = 3 \mathbb{Z}$ under addition. 
  Vänstersidoklassen till $H$ med avseende på 2 är då 
  $2 + 3 \mathbb{Z} = \{ 2+0, \;2+3, \;2+(-3), \;2+6, \;2+(-6), \ldots\}$.
  Eftersom $(\mathbb{Z}, +)$ är abelsk så gäller $2 + 3 \mathbb{Z} = 3 \mathbb{Z} + 2$. 
\end{exmp}

För att slippa kladdiga beräkningar kommer vi från och med nu utelämna opertationen och $ab$ kommer
skrivas istället för $a \circ b$.

\hypertarget{lemma4.1}{}
\begin{mylemma}{}{}
  Låt $G$ vara en grupp och $H$ en delgrupp till denna. Då gäller $hH = H = Hh$ 
  för $h \in H$.
\end{mylemma}
\begin{proof}
  Vi visar först att $hH = H$. 
  Ett godtyckligt element från $hH$ är på formen $hh'$ för $h' \in H$. Eftersom $H$ är 
  en delgrupp så måste $hh'$ vara ett element i $H$, vilket vilket visar att $hH \subseteq H$.

  Låt $g$ vara ett slumpmässigt element i $H$. $g = (hh^{-1})g$ och eftersom 
  $H$ är en delgrupp så gäller $g = (hh^{-1})g = h(h^{-1}g)$. Eftersom $h \in H$ så måste 
  $h^{-1} \in H$ och därför måste $g \in hH$, vilket visar att $H \subseteq hH$.

  Eftersom $H \subseteq hH$ och $hH \subseteq H$ så är $hH = H$. Argumentationen kan 
  replikeras för att visa $Hh = H$, vilket läsaren får gärna göra. 
\end{proof}

\hypertarget{lemma4.2}{}
\begin{mylemma}{}{}
  Låt $G$ vara en grupp och $H$ en delgrupp till denna. 
  Mängden av alla vänster (höger) sidoklasser av $H$ utgör då en partition av $G$.
\end{mylemma}
\begin{proof}
  Vi visar först alla vänstersidoklasser av $H$ utgör en partition av $G$. 
  Eftersom alla element i $gH$ för $g \in G$ är på formen $gh$ för $h \in H$ så måste $gh \in G$
  och alltså gäller $gH \subseteq G$.

  Vi visar nu att två slumpmässiga vänstersidoklasser av $H$ antigen är disjunkta eller identiska.
  Låt
  $g, g' \in G, g \neq g'$ och anta att $gH$ och $g'H$ är olika. För att bevisa att 
  $gH \cap g'H = \emptyset$ så antar vi motsatsen, $gH \cap g'H \neq \emptyset$.
  Detta medför att det finns åtminstone ett element $x$ som finns i både $gH$ samt $g'H$ 
  och därför gäller
  \begin{align*}
    x &= gh, \; h \in H \\
    x &= g'h', \; h' \in H.
  \end{align*}
  Detta medför att $gh = g'h' \iff g = (g'h')h^{-1} = g'(h'h^{-1})$ på grund av assosiativitet.
  $gH$ kan därför skrivas som $gH = g'((h'h^{-1})H)$ och eftersom $h'h^{-1} \in H$ så är 
  $gH = g'H$ enligt \hyperlink{lemma4.1}{lemma 5.8.1}. Detta är dock en motsägelse eftersom vi antog att $gH$ och $g'H$ var 
  olika och därför gäller $gH \cap g'H = \emptyset$.

  Det är uppebart att
  \[G = \bigcup_{g \in G} gH\]
  eftersom $H$ är en delgrupp till $G$ och därför måste $gh$ tillhöra $G$.
  Samma princip kan användas för att bevisa detta för mängden av alla
  högersidoklasser.
\end{proof}

\hypertarget{lag}{}
\begin{mytheo}{Lagranges sats}{}
  Om $H$ är en delgrupp till en ändlig grupp $G$ så är ordningen av $H$ en delare till ordningen av 
  $G$, 
  $|G| = m |H|, \; m \in \mathbb{N}$.
\end{mytheo}
\begin{proof}
  Enligt \hyperlink{lemma4.2}{lemma 5.8.2} så bildar mängden av alla vänstersidoklasser
  till $H$ en 
  partition av $G$ och då gäller
  \[G = \bigcup_{g \in G} gH = g_1H \cup g_2H \cup \ldots \cup g_nH\]
  för $g_1, g_2, \ldots, g_n \in G.$
  Detta medför att 
  \[|G| = |g_1H| + |g_2H| + \ldots + |g_nH|\]
  och eftersom $|g_1H| = |H|$ så gäller 
  \[|G| = m |H|.\]
\end{proof}
\begin{mykol}{}{}
  En grupp med primtalsordning är en cyklisk grupp.
\end{mykol}
\begin{proof}
  Definiera gruppen $(G, \circ)$ så att $|G| = p$ för något primtal $p$. Eftersom 
  $p > 1$ så finns det ett $g$ tillhörande $G$. Bilda den cykliska gruppen 
  $H = (\{g^z \; | \; z \in \mathbb{Z}\}, \circ)$. Eftersom $g \in G$ så $g^z \in G$ 
  för något heltal $z$ på grund av att $G$ är en grupp. $H$ är därför en delgrupp till $G$ och 
  ordningen av $H$ måste dela ordningen av $G$ enligt \hyperlink{lag}{Lagranges sats}.
  Ordningen av $H$ måste antigen vara 1 eller $p$, men eftersom $e, g \in H$ så måste 
  $|H| = p$. $|H| = |G|$ vilket betyder att $H = G$ och $G$ är således cyklisk.
\end{proof}

%ta kanske upp vad alla satser osv. är uppkallde efter. Kanske lite kul att veta detta också. 
\subsection{Gruppverkan och permutationsrepresentation}
Gruppverkan är en väldig viktig gren inom gruppteorin som också kommer att användas 
för att bevisa Banach-Tarski paradoxen. 
Tyvärr så kan denna del vara rätt så svårbegriplig och på grund av dess relevans 
kommer vi därför att gå igenom allt steg för steg för att verkligen gräva upp
de fundamentala ideerna bakom gruppverkan. 

%Skriv även att grupprepresentation ibland brukar användas för att definera 
%gruppverkan. 

%något inom stilen...
%Med hjälp av gruppverkan kan vi associera elementen i en grupp med permutationer,
%vilket också kan ses som gruppverkans syfte. 0

% I detta avsnitt kommer vi även kolla på varför det är relevant för en grupp homomorfism 
% att uppfylla ett specifikt villkor. 
%^kanske nämn detta i homomorfism delen istället. 
Tidiare har vi sätt att varje element i en grupp kan "tänkas" vara en permutation 
av en annan mängd. Men detta ger oss dock ingen nytta om vi inte har ett sätt 
att associera dessa element med permutationer på ett rimligt sätt.
Gruppverkan ger oss just denna associering mellan elementen och permutationer 
av en annan mängd, vilket också kan tänkas vara syftet med gruppverkan. 
Detta syfte framförs dock inte av definitionen och därför kan gruppverkan
tyckas vara svårbegriplig. 
När vi väl har förståt gruppverkan så kommer vi kunna ställa fram en ekvivalent formulering
till gruppverkan som är intuitivare och där syftet presenteras direkt i definitionen.

%Eftersom syftet inte framförs från definitionen kommer vi därför att spendera mycket 
%tid till att hitta syftet... eller något likande kanske. 

\begin{mydef}{Gruppverkan}{}
  En \textit{gruppverkan} av en grupp $G$ på en mängd $X$ är en funktion $f$ från den 
  kartesiska produkten av $G$ och $X$ till $X$, det vill säga $f: G \times X \rightarrow X$,
  som uppfyller följande axiom
  \begin{enumerate}[(i)]
    \item $f(e_G, x) = x \; \forall x \in X$.
    \item $f(gh, x) = f(g, f(h,x)) \; \forall g, h \in G$ och $x \in X$.
  \end{enumerate}
  Funktionen $f(g, x)$ brukar skrivas som $g \cdot x$ och med denna notation 
  blir axiomen
  \begin{enumerate}[(i)]
    \item $e_G \cdot x = x \; \forall x \in X$.
    \item $(gh) \cdot x = g \cdot (h \cdot x) \; \forall g, h \in G$ och $x \in X$.
  \end{enumerate}
  Om en grupp $G$ verkar på en mängd $X$ så att $g \cdot x = x$ för ett $g \in G$ skillt från enhetselementet och $x \in X$ så säger vi att $x$ är en 
  \textit{icke trivial fixerad punkt av} $G$.
\end{mydef}
Först och främst måste vi förstå vad en gruppverkan egentligen gör. 
Gruppverkan är en funktion som assocerar ett ordnat par $(g, x), \; g \in G, \; x \in X$
med ett element i mängden $X$. Helt intuitivt kan man tänka $f(g, x)$ eller 
$g \cdot x$ som en slags operation som sammansätter $g$ med $x$ för att få tillbaka ett 
element i $X$. Det är faktiskt precis så här man definiera en binär operation mer formellt. 

\begin{mydef}{Binär operation}{}
  En \textit{binär operation} på en mängd $X$ är en funktion $f: X \times X \rightarrow X$. 
\end{mydef}
En binär operation är alltså en funktion som mappar ett ordnat par med ett annat element 
i mängden. Om $f$ är den binära operationen addition så brukar vi dock inte skriva 
$f(1, 2) = 3$, utan vi har valt att skriva $1 + 2 = 3$ istället, vilket också 
är anledningen till varför man skriver $f(g, x)$ som $g \cdot x$ när man talar om gruppverkan. 

Notera att en binär operation sammansätter två element med varandra för att få tillbaka 
ett element i samma mängd och är därför sluten. Om $G$ är en grupp under en binär operation 
så uppfylls alltså gruppaxiomet Slutenhet direkt. På grund av detta så brukar 
axiomet Slutenhet helt utelämnas från definitionen. 
%skriv att om man nämner att gruppen är under en binär operation så behöver man inte 
%kolla på slutenhet. 

För att skapa en associering mellan elementen av en grupp $G$ och permutationer av 
en annan mängd $X$ så måste vi först skapa en funktion.
%just i steget nedan är precis det jag gör med permrep. Det är inte ett "intuitivare sätt"
%utan precis samma sak. 
Låt $f(g) = \sigma_g$ där 
$g \in G$ och där $\sigma_g$ är en permutation av mängden $X$. Följande sats visar 
att för $x \in X$ så är $\sigma_g(x) = g \cdot x$ en permutation av $X$. 

\hypertarget{sats4.9.1}{}
\begin{mytheo}{}{}
  $\sigma_g(x) = g \cdot x$ är en permutation av $X$.
\end{mytheo}
\begin{proof}
  Per definition så är $g \cdot x$ ett element av $X$ och därför går $\sigma_g$ från 
  $X$ till $X$. Eftersom en funktion som endast är injektiv eller surjektiv inte kan ha någon invers 
  så räcker det med att visa att $\sigma_{g^{-1}}$ är inversen till $\sigma_g$ 
  för att visa att $\sigma_g$ är en 
  bijektion. Nedan visar vi att $\sigma_{g^{-1}}(\sigma_g(x)) = x.$
  \[\sigma_{g^{-1}}(\sigma_g(x)) = \sigma_{g^{-1}}(g \cdot x) = g^{-1} \cdot (g \cdot x)\]
  och enligt axiomen får vi
  \[g^{-1} \cdot (g \cdot x) = (g^{-1}g) \cdot x = e_G \cdot x = x.\]
  På samma sätt kan man visa att $\sigma_g(\sigma_{g^{-1}}(x)) = x.$
  \[\sigma_g(\sigma_{g^{-1}}(x)) = g \cdot (g^{-1} \cdot x) = (g g^{-1}) \cdot x = x.\]
\end{proof}
Vi kan börja se varför axiomen för gruppverkan är så viktiga. Utan dem skulle vi inte 
kunna associera element med permutationer och hela syftet med gruppverkan skulle försvinna. 

För att ta detta ett steg vidare kan vi nu skapa permutations gruppen 
$G' = \{\sigma_g \; | \; g \in G\}$ under komposition $\circ$ som kommer att agera som 
en "permutations variant" av $G$. Vi behöver naturligtvist också visa att $G'$ är en grupp
och detta görs nedan. 
\begin{enumerate}[(i)]
  \item \textbf{Slutenhet.} För $g, h \in G$ och $x \in X$ gäller 
  $(\sigma_g \circ \sigma_h) (x) = \sigma_g(\sigma_h(x)) = \sigma_g(h \cdot x)$. Eftersom 
  $h \cdot x \in X$ så är $\sigma_g(h \cdot x) \in G'$ och axiomet uppfylls.
  \item \textbf{Assosiativitet.} Detta axiom uppfylls enligt \hyperlink{ass}{sats 5.1.1}
  \item \textbf{Enhetselementet.} Enhetselementet är $\sigma_{e_G}$ eftersom för 
  $g \in G$ och $x \in X$ så gäller $(\sigma_{e_G} \circ \sigma_g) (x) = 
  e_G \cdot (g \cdot x) = \sigma_g(x)$ och axiomet uppfylls. 
  \item \textbf{Inverser.} Om $g \in G$ så finns även $g^{-1}$ i $G$ och därför finns 
  $\sigma_{g^{-1}}$ i $G'$. Beviset av \hyperlink{sats4.9.1}{sats 5.9.1} visar 
  att inversen till $\sigma_g$ är $\sigma_{g^{-1}}$ och axiomet uppfylls. 
\end{enumerate}
Men för att $G'$ verkligen ska motsvara $G$ så måste deras "operationer överensstämma", det 
vill säga $\sigma_{gh} = \sigma_g \circ \sigma_h$ för $g, h \in G$.
Figuren nedan visar vad detta betyder visuellt.

\begin{center}{}
  \begin{tabular}{c | c c c}
     &  & $h$ &\\
    \cline{1-4}
    &  &  & \\
    $g$ &  & $gh$ & \\
    &  &  & \\
  \end{tabular} 
  \quad
  \begin{tikzpicture}
    % \node[font=\large] at (0.5, -0.2) {$\varphi : G \rightarrow G'$};
    \draw[-latex] (0, -1) -- (1.5, -1) node at (0.75, -0.7) {$f$} node at (-0.3, -1) {$G$}
    node at (1.8, -1) {$G'$};
  \end{tikzpicture}
  \quad
  \begin{tabular}{c | c c c}
    $\circ$ &  & $\sigma_h$ &\\
    \cline{1-4}
    &  &  & \\
    $\sigma_g$ &  & $\sigma_g \circ \sigma_h$ & \\
    &  &  & \\
  \end{tabular} 
\end{center}
Om $\sigma_{gh} \neq \sigma_g \circ \sigma_h$ så skulle det vara svårt att jämföra elementen i 
$G$ med $G'$ och eftersom vi strävar efter en koppling mellan dessa grupper så
är detta förhållande nödvändig. Satsen nedan bevisar detta. 

\hypertarget{sats.4.9.2}{}
\begin{mytheo}{}{}
  $\sigma_{gh} = \sigma_g \circ \sigma_h$.
\end{mytheo}
\begin{proof}
  Vi kollar på högerledet och jobbar oss fram till vänsterledet.
  \[H.L = (\sigma_g \circ \sigma_h)(x) = g \cdot (h \cdot x) = (gh) \cdot x = \sigma_{gh}(x) = V.L\]
  Notera användingen av axiom II.
\end{proof}

Sammanfattningsvis har vi skapat en grupp $G$ och med hjälp av gruppverkan 
skapat en "permutations variant" av denna grupp som vi kallad för $G'$. Med hjälp av 
detta kan vi gå fram och tillbaka mellan grupperna och välja om vi vill jobba 
med permutationer eller "vanliga element". För att göra saker och ting lite mer tydligare 
så kan vi tänka på $G$ som gruppen av heltal under addition. Vi har tidigare sätt 
att denna grupp är isomorfisk med den oändliga cykliska gruppen, som alltså är en 
permutationsgrupp. En lämplig "permutations variant" av gruppen av heltal under addition 
är därför den oändliga cykliska gruppen. 

För att ställa fram en ekvivalent formulering till gruppverkan med samma syfte 
så kan vi direkt skapa funktionen
$\varphi: G \rightarrow Sym(X)$
som definieras av $\varphi(g) = \sigma_g$.
I detta fall blir $G'$, som är "permutations varianten" av $G$, $Im(\varphi) = 
\{\sigma_g \; | \; g \in G\}$. Men, precis som vid \hyperlink{sats.4.9.2}{sats 5.9.2}, så 
vill vi skapa en koppling mellan $G$ och $G'$ och därför måste 
\[\sigma_{gh} = \sigma_g \circ \sigma_h\]
och per definition av $\varphi$ är detta ekvivalent med 
\[\varphi(gh) = \varphi(g) \circ \varphi(h).\]
Detta är nämligen villkoret som 
en funktion måste uppfylla för att den ska anses vara en homomorfism. Detta betyder att 
$\varphi$ måste vara en homomorfism. Det vi har gjort nu heter 
permutationsrepresentation och definieras nedan.

\begin{mydef}{Permutationsrepresentation}{}
  En \textit{permutationsrepresentation} av en grupp $G$ på en mängd $X$ 
  är en homomorfism från $G$ till den symmetriska gruppen av $X$:
  \[\varphi: G \rightarrow Sym(X).\]
\end{mydef}

Permutationsrepresentationer och gruppverkan är alltså starkt kopplade med varandra 
eftersom de delar samma syfte. Notera att vi gick från gruppverkan till grupprepresentation
och att vi kan gå baklänges och skapa en gruppverkan från en grupprepresentation. 
Vi kan alltså skapa den ena från den ena, vilket betyder att de två är ekvivalenta med varandra
och ibland brukar även visa texter definieras gruppverkan precis så som vi definierade 
grupprepresentation.

Om vi minns tillbaka till Cayles sats, som påstår att varje grupp är isomorfisk med en delgrupp
av $Sym(G)$, så kanske man inser att det finns ett till sätt att bevisa den med hjälp av 
gruppverkan och permutationsrepresentationer. Eftersom de två är ekvivalenta så kan vi 
först visa att $G$ verkar på sig själv enligt $g \cdot g' = g \circ g'$ 
som då kommer skapa en homomorfism
$\varphi: G \rightarrow Sym(G)$ som definieras av $\varphi(g) = \sigma_g$
där $\sigma_g(g') = g \cdot g' = g \circ g'$. Sedan återstår det 
bara att visa att $\varphi$ är en injektion eftersom $G$ blir då isomorfisk med $Im(\varphi)$, 
som är en delgrupp av $Sym(G)$. Alla steg till beviset är nu upplagda och läsaren får fylla i detaljerna.

\begin{exmp}
  Betrakta gruppen $Sym(M)$ under komposition $\circ$ där 
  $M = \{1, 2, 3\}$. $Sym(M)$ verkar då på mängden $M$
  genom funktionen $g \cdot x = g(x)$, eller om man så vill $f(g, x) = g(x)$, 
  där $g \in G$ och $x \in M$. Detta eftersom båda axiomen uppfylls:
  \begin{enumerate}[(i)]
    \item $e_G \cdot x = e_G(x) = x$ för alla $x \in M$.
    \item $(g \circ h) \cdot x = g(h(x)) = g \cdot h(x) = g \cdot (h \cdot x).$
  \end{enumerate}
  Sätt ifrån ett permutationsrepresentations perspektiv så är 
  $\varphi: Sym(M) \rightarrow Sym(M)$ definierad av $\varphi(g) = g, \; g \in Sym(G)$
  en homomorfism och därför måste $Sym(M)$ verka på $M$.
\end{exmp}

%ta bort denna. C verkar på Z genom sigma(z) = sigma cdot z, precis som i förra exemplet. 
\begin{exmp}
  Den oändliga cykliska gruppen $C$ under komposition $\circ$ verkar på alla heltal $\mathbb{Z}$
  genom funktionen $\sigma^n \cdot m = n + m$ för $n, m \in \mathbb{Z}$.
  Detta eftersom båda axiomen uppfylls:
  \begin{enumerate}
    \item $\sigma^0 \cdot m = 0 + m = m$.
    \item $(\sigma^n \circ \sigma^z) \cdot m = \sigma^{n + z} \cdot m = (n + z) + m = 
    \sigma^n \cdot (\sigma^z \cdot m)$.
  \end{enumerate}
  Sätt ifrån ett permutationsrepresentations perspektiv så är 
  $\varphi: C \rightarrow Sym(\mathbb{Z})$ definierad av $\varphi(\sigma^n) = \sigma^n, \; 
  n \in \mathbb{Z}$ en homomorfism och därför måste $C$ verka på $\mathbb{Z}$.
\end{exmp}

\begin{exmp}
  Den dihedrala gruppen $D_{2n}$ verkar på en $n$-hörning då permutationerna i $D_{2n}$ kan tillämpas på en $n$-hörning 
  för att till exempel spegla den.
\end{exmp}

\subsubsection{Banor}
Med den förståelsen vi nu har om gruppverkan så kan vi ägna vår tid åt banor
\begin{mydef}{Banor}{}
  Om $G$ verkar på mängden $X$ och $x \in X$ är \textit{banan} för $x$ mängden 
  \[\orbit_x \equiv \{g \cdot x \; | \; g \in G\}.\]
\end{mydef}
Tidigare har vi definierat funktionen $\sigma_g(x) = g \cdot x$ och även bevisat i 
\hyperlink{sats4.9.1}{sats 5.9.1} att 
denna är en permutation av $X$. Med denna definition kan vi uttrycka banan för $x$ som 
$\orbit_x = \{\sigma_g(x) \; | \; g \in G\}$ och 
således är ett elements bana mängden av alla möjliga destinationer under alla permutationer 
$\sigma_g$.

\begin{exmp}
  Om $M = \{1, 2, 3\}$ så verkar $Sym(M)$ under komposition $\circ$ på $M$ 
  genom funktionen $g \cdot x = g(x), \; g \in Sym(M), x \in M$ enligt tidigare resultat. Banan för 
  1 är då $\orbit_1 = \{g \cdot x \; | \; g \in Sym(M)\} = \{g(x) \; | \; g \in Sym(M)\}
  = \{1, 2, 3\}$ eftersom $Sym(M)$ innehåller alla möjliga permutationer på $M$.
  Detta betyder även att $\orbit_1 = \orbit_2 = \orbit_3$. För en visualisering så
  kan man kolla på figurerna i \hyperlink{exempel4.2}{exempel 5.2}.
\end{exmp}

\begin{exmp}
  Gruppen $G = \{e, \tau_{12}, \tau_{13}\}$ under komposition $\circ$ verkar på 
  mängden $M = \{1, 2, 3\}$ genom funktionen $g \cdot x = g(x), \; g \in G, x \in M$. 
  Banan för 2 är då $\orbit_2 = \{1, 2\}$ och banan för 1 är $\orbit_1 = \{1, 2, 3\}$.
\end{exmp}

\begin{mytheo}{}{}
  Låt $G$ vara en grupp som verkar på mängden $X$. Mängden av alla banor av $x \in X$
  utgör då en partition av $X$. 
\end{mytheo}
\begin{proof}
  $\orbit_x$ är en delmängd till $X$ eftersom $g \cdot x \in X$ för $g \in G$ och $x \in X$.
  Vi visar nu att mängden $\{\orbit_x \; | \; x \in X\}$ är parvis disjunkt. 
  Anta att $\orbit_x$
  och $\orbit_{x'}$ för $x' \in X$ inte är disjunkta. Då måste det finnas 
  ett element $y$ som finns i både $\orbit_x$ och $\orbit_{x'}$ och då gäller 
  \begin{align*}
    y &= g \cdot x \\
    y &= g' \cdot x'.
  \end{align*}
  för $g' \in G.$ Detta ger att 
  \begin{align*}
    g \cdot x &= g' \cdot x' \iff \\
    g^{-1} \cdot (g \cdot x) &= g^{-1} \cdot (g' \cdot x')
  \end{align*}
  och enligt axiomen får vi 
  \begin{align*}
    g^{-1} \cdot (g \cdot x) &= g^{-1} \cdot (g' \cdot x') \iff \\
    (g^{-1} g) \cdot x &= (g^{-1} g') \cdot x' \iff \\
    x &= (g^{-1} g') \cdot x'.
  \end{align*} 
  På samma sätt kan man visa att $x' = (g'^{-1}g) \cdot x$ genom att 
  "multiplicera" med $g'^{-1}$ på båda sidorna om $g \cdot x = g' \cdot x'$. 
  Eftersom $g^{-1} g'$ och $g'^{-1}g$ är båda element i $G$ så är 
  $x \in \orbit_{x'}$ samt $x' \in \orbit_x$ och därför är även $g \cdot x \in \orbit_{x'}$
  och $g \cdot x' \in \orbit_{x}$. Detta betyder att $\orbit_x \subseteq \orbit_{x'}$ och att 
  $\orbit_{x'} \subseteq \orbit_x$ vilket medför att $\orbit_x = \orbit_{x'}$.
  Eftersom två banor antigen är disjunkta eller identiska så gäller 
  \[\bigcap_{x \in X} \orbit_x = \emptyset.\]
  Då alla $\orbit_x$ är delmängder till $X$ och eftersom $x \in \orbit_x$ för alla $x \in X$ så är 
  \[\bigcup_{x \in X} \orbit_x = X\]
  som slutför beviset.
\end{proof}

Följande lemma kommer att användas för en sats längre fram i texten. 

\begin{mylemma}{}{}
  Låt $G$ vara en grupp som verkar på en mängd $X$ utan icke triviala fixerade punkter. Antag att $R \subseteq X$
  innehåller exakt ett element från varje bana av $G$. Låt $P$ vara mängden av alla sidoklasser till $R$. Då utgör $P$ en partition av $X$.
\end{mylemma}

\hypertarget{lemma6.9.1}{}
\begin{proof}
  Låt $G$ vara en grupp som verkar på $X$ utan icke triviala fixerade punkter. Antag att $R \subseteq X$
  innehåller exakt ett element från varje bana av $G$. Låt $P$ vara mängden av alla sidoklasser till $R$. 
  Låt även $gR$ och $g'R$ vara godtyckliga element i $P$ och antag att $gR \cap g'R \neq \emptyset$. 
  Då finns det ett $x \in gR \cap g'R$ och $x$ kan således skrivas som $x = gr$ eller $x = g'r'$ för $r \in R$ och $r' \in R$. 
  Om $r \neq r'$ så finns $x$ i två olika banor, som är en motsägelse enligt ovanstående sats. Vi drar slutsatsen att $gr = g'r$
  och eftersom $G$ verkar på $X$ utan icke triviala fixerade punkter så är $g = g'$ som betyder att $gR = g'R$ och därför är alla element i $P$
  parvis disjunkta.

  För varje $x \in X$ så låter vi $y \in \orbit_x \cup R$. Per definitionen så är $g \cdot x = y$ för $g \in G$ som ger oss att 
  $x = g^{-1} \cdot y$. Detta betyder att $x \in g^{-1} \cdot R \equiv g^{-1}R$. Nu är $X \subseteq \bigcup P$. Men varje element i $P$ 
  är en delmängd av $X$ och därför måste även unionen av alla element i $P$ också vara en delmängd av $X$. Vi drar slutsatsen att $X = \bigcup P$
  som slutför beviset.
\end{proof}

\section{Oändligheten}
% Här ska jag skriva om uppräkneliga mängder, ouppräkneliga mängder och Hilberts hotel. Dessa är nödvändiga för beviset av paradoxen. Hilberts hotel
% kommer såklart inte användas vid beviset eftersom det skulle vara oformellt. Jag kommer därimot referera till den. Hilberts hotel kommer även användas om
% frågeställningen "Går det att förstå paradoxen utan matematik?" väljs. 
Det första som vi måste observera i detta avsnitt är att oändligheten inte är ett tal. Om det skulle vara ett tal, vilket tal skulle det isåfall vara?
Hur skulle man definiera det? Det kan förstås inte vara det sista talet reella talet då det finns oändligt många tal. 
Det kan inte heller vara det största reella talet då jag alltid kan addera 1 till det för att få ett större tal. Vi träffar alltså alltid på problem 
när vi försöker definiera oändligheten som ett tal på ett vettigt sätt. 
Oändligheten är snarare en abstrakt idé som går att väva in i matematiken och eftersom det inte är ett tal så kan man inte heller förvänta 
sig att den har vanliga "talegenskaper". På grund av detta så kan oändligheten ibland strida mot vår intuition då vi är vana vid hur vanliga tal 
beter sig. Ett exempel på detta är Hilberts hotell 

En dag kom en ung vacker prinsessa sent en regnig kväll in på Hillberts hotell som är uppbyggt av oändligt många rum.
Den vackra prinsessan kom in på hotellet och frågade receptionisten om det fanns något ledigt rum. Tyvärr var dock Hilberts hotell fullbokat, 
men receptionisten kom på en lösning! Hon bad respektive innebående att flytta ett rumsnummer högre än det rum repsektive person befann sig. 
Detta innebar att rum nummer 1 blev ledigt då det finns oändligt många rum
och den som bodde i rum nummer 1 har flyttat till rum nummer 2, den som bodde i rum nummer 2 har flyttat till rum nummer 3
och så vidare, precis som figuren nedan försöker illusterara.  

\begin{center}
  \begin{tikzpicture}[scale=1.4]
    % \draw (0,0,0) --  (2,0,0)  node[pos=1.05]{$x$};
    % \draw (0,0,0) -- (0,3,0) node[pos=1.05]{$y$};
    % \draw (0,0,0) -- (0,0,2) node[pos=1.1]{$z$};

    % \draw[thick] (-1.5, 0, -0.8) -- (0, 0, 0) -- (0, 2, 0) -- (-1.5, 2, -0.8) -- (-1.5, 0, -0.8);
    % \draw[thick] (0, 0, 0) -- (5, 0, -1.7);
    % \draw[thick] (5, 2, -1.7) -- (0, 2, 0);
    % \draw[thick] (3.5, 2, -2.5) -- (-1.5, 2, -0.8);
    % \node[font=\Large] at (5.5, 1, -2) {$\mathbin{\rotatebox[origin=c]{7}{$\cdots$}}$};

    \draw[thick] (-0.3, 0) -- (6, 0);
    \foreach \x in  {0, 0.5,...,6}{
      \draw[thick] (\x-0.2, 0) -- (\x, -0.3);
    }
    \node[] at (6.3, 0.5) {$\cdots$};

    \foreach \d in  {1,2,...,5}{
      \draw[thick, fill=gray] (\d, 0) -- (\d, 1) -- (\d + 0.7, 1) -- (\d + 0.7, 0);
      \draw[fill=brown] (\d + 0.6, 0.5) circle (0.05);
      \node[font=\Large, xscale=1.5, yscale=1.4] at (\d-0.1, 1.2) {$\curvearrowright$};
    }

    \draw[thick] (0, 0) -- (0, 1) -- (0.7, 1) -- (0.7, 0);
    \draw[fill=brown] (0.6, 0.5) circle (0.05);
  \end{tikzpicture}
\end{center}

Detta resultat kan kännas konstigt men vi får inte glömma att oändligheten inte har vanliga "talegenskaper" då det inte är ett tal. 
Om Hillberts hotell innehöll ändligt många rum så skulle receptionistens lösning inte fungera. Det som Hillbert introducerar i 
denna historia är den minsta oändligheten, $\aleph_0$, som är antalet existerande naturliga tal (kardinaliteten av $\mathbb{N}$). 
Till exempel så är $\aleph_0 = \aleph_0 + 1$ som presenterades i Hillberts hotell. Det finns dock större oändligheter än $\aleph_0$. 
För att förstå detta så observerar vi först att vi kan räkna upp det naturliga talen, 1, 2, 3, osv. Detta gäller dock inte hos de reella talen. 
Ta till exempel intervallet från 0 till 1. Hur ska man börja räkna från 0 till 1? Det första reella talet efter 0 är $0.000\cdots$ som 
tillslut slutar med en etta efter oändligt många nollor. Intervallet 0 till 1 innehåller alltså fler tal än
storleken av de naturliga talen! För att särskilja olika oändligheter så används begreppen \textit{uppräkneliga mängder} och \textit{ouppräkneliga mängder}
(även kallat överuppräknelig) som följande definition definierar.

\begin{mydef}{}{}
  En mängd sägs vara \textit{uppräknelig} om det existerar en bijektion från den mängden till $\mathbb{N}$. En mängd sägs vara 
  \textit{ouppräknelig} om det inte existerar en injektion från den mängden till $\mathbb{N}$.
\end{mydef}
Om en mängd är uppräknelig så har den alltså kardinaliteten $\aleph_0$. En 
\linebreak
ouppräknelig mängd är dock för stor för att vara uppräknad på 
detta sätt. Ett exempel på en ouppräknelig mängd är $\mathbb{R}$. I detta sammanhang kan en diskret funktion definieras som 
en funktion vars definitionsmängd är uppräknelig. I denna text ska vi inte definiera kontinuerliga funktioner. Det 
är dock viktigt att inte blanda ihop dessa. Detta är något som skolboks (matematik 3) författare tydligen inte kan begripa. 

\section{Banach-Tarski paradoxen}
Nu när vi har tagit upp oändligheten så kanske det inte känns så konstigt att vi faktiskt kan duplicera en sfär då 
oändligheten har väldigt konstiga egenskaper. För att bevisa detta matematiskt måste vi först ta upp urvalsaxiomet.
\subsection{Urvalsaxiomet}
Informellt så säger urvalsaxiomet ($\mathsf{AC}$, axiom of choice) att givet en kollektion av paket, där varje innehåller åtminstone ett element, så 
är det möjligt att göra en selektion av exakt ett objekt från varje paket, även om antalet paket är oändligt. Axiomet kan anges på följande sätt.

\begin{myaxiom}{}{}
  En \textit{urvalsfunktion} är en funktion $f$ vars definitionsmängd $X$ är en kollektion av icke tomma mängder så att för varje 
  mängd $A \in X$ så är $f(A)$ ett element av $A$. Urvalsaxiomet säger att för varje mängd $X$ innehållande icke tomma mängder så existerar 
  det en urvalsfunktion vars definitionsmängd är $X$. Med symboler 
  \[ \forall X \biggl( \emptyset \notin X \implies \exists f: X \rightarrow \bigcup X \; | \; \forall A \in X \; f(A) \in A  \biggr).\]
\end{myaxiom}
Man kan tänka sig att mängden $X$ i axiomet ovan är en låda som innehåller paket som inte är tomma. Urvalsfunktionen kan då ses som en robot. 
Man kan peka på en av lådorna och roboten (urvalsfunktionen) gräver in sig i den lådan, öppnar ett paket i den lådan, och tar upp ett element i 
det paketet. Symbolvarianten av $\mathsf{AC}$ stämmer alltså överens med den informella påståendet av $\mathsf{AC}$. 

\subsection{Paradoxala grupper och andra förkunskaper}
Vi börjar med en massa definitioner.

\begin{mydef}{}{}
  Låt $G$ vara en grupp. Ett \textit{ord} $w$ i $G$ är ett uttryck innehållande element i $G$, det vill säga 
  \[w = g_1^{\epsilon_1} \cdots g_n^{\epsilon_n} \text{ där } g_i \in G \text{ och } \epsilon_i \in \{1, -1\}.\]  
  Ett ord är \textit{reducerat} om $g_i^{\epsilon_i} \neq g_{i+1}^{-\epsilon_{i+1}}$. Med andra ord så kan ett reducerat ord inte innehålla 
  ord på formen $xx^{-1}$ eller $x^{-1}x$ för $x \in G$. 
\end{mydef}

\begin{mydef}{}{}
  Låt $G$ vara en grupp och antag att $X \subseteq G$. \textit{Delgruppen som genereras av} $X$ är gruppen
  \[\langle X \rangle \equiv \{x_1^{\epsilon_1} \cdots x_n^{\epsilon_n} \; | \; x_i \in X, \epsilon_i \in \{1, -1\}, n \in \mathbb{N}  \}.\]
\end{mydef}
Notera skillnaden mellan en grupp som genereras av ett \textit{element} ($\langle x\rangle \equiv \{x^n \; | \; n \in \mathbb{N}\}$)
och en grupp som genereras av en \textit{mängd}, som definitionen ovanför definierar.

\begin{mydef}{}{}
  En grupp $G$ är en \textit{fri grupp} om det existerar en delmängd $X$ av $G$ så att $\langle X \rangle = G$ och 
  där varje icke tomt reducerat ord i $\langle X \rangle$ definierar ett element i $G$ som är skilt från enhetselementet. Kardinaliteten av $X$
  kallas för \textit{ranken} (eng. \textit{rank}) för $G$
\end{mydef}

\begin{mydef}{}{}
  Gruppen av alla rotationer kring origo i ett tredimensionellt Euklidiskt rum ($\mathbb{R}^3$) under komposition (matris multiplikation) är 
  kallad för den \textit{speciella ortogonalgruppen} i tre dimensioner, $\text{SO}_3$.
\end{mydef}

\textbf{Notation:} Om gruppen $G$ verkar på mängden $X$ så kommer vi skriva $g \cdot A \equiv \{g \cdot a \; | \; a \in A\}$
som $g(A)$ för $g \in G$ och $A \subseteq X$. Detta för att förtydliga att $g$ inducerar en permutation på mängden $A$.
\begin{mydef}{}{}
  Låt $G$ vara en grupp som verkar på mängden $X$ som har delmängderna $A$ och $B$. 
  Om det finns två mängder $\{A_i\}_{i = 1}^k \equiv \{A_1, \ldots, A_k\}$ och $\{B_i\}_{i = 1}^k$ där elementen 
  utgör en partition av $A$ respektive $B$ och om det existerar en \textit{multimängd} (eng. multi-set, en mängd där repetition får förekomma) 
  $\{g_i \in G\}_{i = 1}^k$ så att $g_i(A_i) = B_i$ för alla $i = 1, \ldots, k$ 
  så är $A$ $G$\textit{-equidekomposibel} (eng. \textit{equidecomposible}) med $B$ med $k$ bitar. 
\end{mydef}

\begin{exmp}
  Vi kan börja med en mängd $A$ som kan represetera en kvadrat som visas i nedanstående figur. 

  \begin{center}
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=4, draw, rotate=0, scale=6] at (0,0){};
      \filldraw[myblue, opacity = 0.3] (-1, -1) -- (1, -1) -- (1, 1);
      \filldraw[blue, opacity = 0.3] (-1, -1) -- (-1, 1) -- (1, 1);
      % \draw[help lines](-5,5) grid (5,-6);  
    \end{tikzpicture}
  \end{center}
  $A$ kan till exempel innehålla koordinaterna för kvadratens hörn eller liknande. Det blåa och det gula området utgör en partition av 
  hela kvadraten och dessa områden kan tänkas vara element i mängden $\{A_i\}_{i = 0}^k$ i definitionen. Vi låter nu 
  $\text{SO}_2$ verka på $A$ så att vi kan rotera dessa områden som figuren nedan visar.

  \begin{center}
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=4, draw, rotate=0, scale=6] at (0,0){};
      \filldraw[myblue, opacity = 0.3] (-1, -1) -- (1, -1) -- (1, 1);
      \filldraw[blue, opacity = 0.3] (-1, -1) -- (-1, 1) -- (1, 1);
      % \draw[help lines](-5,5) grid (5,-6);  
      \draw[-latex] (1.7, 0) -- (3.4, 0) node[above, midway] {$g \in \text{SO}_3$};
    \end{tikzpicture}
    \quad
    \begin{tikzpicture}
      % \node[regular polygon,regular polygon sides=4, draw, rotate=0, scale=6] at (0,0){};
      \filldraw[myblue, opacity = 0.3] (-1, -1) -- (1, -1) -- (1, 1);
      \filldraw[blue, opacity = 0.3] (1, -1) -- (3, -1) -- (1, 1);
      \draw (-1, -1) -- (1, 1) -- (3, -1) -- (-1, -1);
      % \draw[help lines](-5,5) grid (5,-6);  
    \end{tikzpicture}
  \end{center}
  Rotationen $g$ i figuren ovan är alltså ett element i multimängden $\{g_i \in \text{SO}_3\}_{i = 1}^k$ och
  de färgade områderna i triangeln är element i mängden $\{B_i\}_{i = 1}^k$ i definitionen. Då det krävs två rotationer, $e$ och $g$ i figuren ovan, 
  och $k = 2$ där $k$ härstammar från definitionen så kan vi dra slutsatsen att rektangeln är $\text{SO}_3$-equidekomposibel med triangeln med 2 bitar. 
  Vi kan alltså säga att två "figurer" är equidekomposibla om det ena kan skäras upp i mindre bitar och om dessa bitar sedan kan permuteras för att 
  forma den andra figuren.
\end{exmp}

\begin{mydef}{}{}
  Låt $G$ vara en grupp som verkar på mängden $X$ och antag att $E \subseteq X$. Vi säger att 
  $E$ är $G$-\textit{paradoxal} (eng. \textit{paradoxical}) om det existerar två mängder $\{A_i \subseteq E\}_{i = 1}^n$ och $\{B_j \subseteq E\}_{j = 1}^m$
  vars element är parvis disjunkta och om det finns två multimängder $\{g_i \in G\}_{i = 1}^n$ och $\{g_j' \in G\}_{j = 1}^m$ så att 
  \[E = \bigcup_{i = 1}^n g_i(A_i) \quad \text{och} \quad E = \bigcup_{j = 1}^m g_j'(B_j).\]
  När en grupp är paradox med avseende på sig själv så kallas denna för en \textit{paradoxal grupp}.
\end{mydef}

Om en "figur" är paradoxal så kan vi alltså duplicera den, det vill säga göra två identiska kopior av den. Nästkommande sats 
blir nödvändig för att bevisa Banach-Tarski paradoxen. 

\hypertarget{sats8.2.1}{}
\begin{mytheo}{}{}
  Låt $G$ vara en grupp som verkar på mängen $X$ och antag att $E$ och $E'$ är $G$-equidekomposibla ändliga delmängder av $X$
  med $k$ bitar. Om $E$ är $G$-paradoxal så är också $E'$.
\end{mytheo}

\begin{proof}
  Definiera alla mängder som vi gjort ovan. Då existerar det $\{A_i \subseteq E\}_{i = 1}^n$ och $\{B_j \subseteq E\}_{j = 1}^m$
  vars element är parvis disjunkta samt mängderna $\{g_i \subseteq G\}_{i = 1}^n$ och $\{g'_j \subseteq G\}_{j = 1}^m$ så att 
  $E = \bigcup_{i = 1}^n g_i(A_i)$ och $E = \bigcup_{j = 1}^m g'_j(B_j)$. Då $E'$ är $G$-equidekomposibel med $E$ med $k$ bitar så existerar 
  det två mängder $\{E_i\}_{i = 1}^k$ och $\{E'_i\}_{i = 1}^k$ vars element utgör en partition av $E \subset X$ respektive $E' \subset X$.
  Det finns även en multimängd $\{h_l \in G\}_{l = 1}^k$ så att $h_l(E_l) = E_l'$ för alla $l = 1, \ldots, k$. Då 
  $\{g_i(A_i)\}_{i = 1}^n, \; \{g'_j(B_j)\}_{j = 1}^m$ och $\{E_l\}_{l = 1}^k$ är parvis disjunkta så är även mängderna 
  \[ \{g_i(A_i) \cap E_l \; | \; g_i(A_i) \cap E_l \neq \emptyset \; \forall i = 1, \ldots, n, \forall l = 1, \cdots k\} \]
  och
  \[ \{g_j'(A_j) \cap E_l \; | \; g_j'(A_j) \cap E_l \neq \emptyset \; \forall j = 1, \ldots, n, \forall l = 1, \cdots k\} \]
  parvis disjunkta. Vidare gäller även
  \[ \bigcup_{l = 1}^k \bigcup_{i = 1}^n (h_l(g_i(A_i) \cap E_l)) = E' \quad \text{och} \quad
  \bigcup_{l = 1}^k \bigcup_{j = 1}^m (h_l(g_j'(A_j) \cap E_l)) = E'.\]
  Detta kan visas genom att använda faktumet att $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$. Att bevisa att den distributiva lagen 
  gäller för snitt lämnas som en övning till läsaren. Detta kan göras med ett direkt bevis eller genom att rita upp en sanningstabell.
\end{proof}

Den ovanstående satsen kan förstås intuitivt men förstås så behövs detta bevisas formellt. 

\hypertarget{sats8.2.2}{}
\begin{mytheo}{}{}
  Varje frigrupp av rank 2 är en paradoxal grupp. 
\end{mytheo}

\begin{proof}
  Låt $F \equiv \langle X \rangle$ vara en frigrupp där $X = \{a, b\}$. Gruppen $F$ innehåller alltså alla möjliga ord som kan bildas 
  av $a, b, a^{-1}$ och $b^{-1}$. Låt $F$ verka på sig själv och låt $w_a, w_b, w_{a^{-1}}, w_{b^{-1}}$ vara mängder av alla reducerade 
  ord i $F$ som startar på motsvarande index. Naturligtvist så utgör dessa en partition av $F$ 
  och ekvationen $F = w_a \cup w_b \cup w_{a^{-1}} \cup w_{b^{-1}} \cup \{e\}$ gäller.
  Det är trivialt att $a^{-1}w_a = w_a \cup w_b \cup w_{b^{-1}} \cup \{e\}$ och att $b^{-1}w_b = w_a \cup w_b \cup w_{a^{-1}} \cup \{e\}$
  som medför att $F = a^{-1} w_a \cup w_{a^{-1}}$ samtidigt som $F = b^{-1}w_b \cup w_{b^{-1}}$ som slutför beviset.
\end{proof}

\hypertarget{sats8.3.2}{}
\begin{mytheo}{}{}
  Om $G$ är en paradoxal grupp som verkar på mängden $X$ utan icke triviala fixerade punkter så är $X$ $G$-paradoxal. 
\end{mytheo}

\begin{proof}{}{}
  Låt $G$ vara en paradoxal grupp som verkar på mängden $X$ utan icke triviala fixerade punkter. Då existerar det 
  två mängder $\{A_i \subseteq G\}_{i = 1}^n$ och $\{B_j\}_{j = 1}^m$ vars element är parvis disjunkta och två multimängder 
  $\{g_i \in G\}_{i = 1}^n$ och $\{g_j' \in G\}_{j = 1}^m$ så att $G = \bigcup_{i = 1}^n g_i(A_i)$ och $G = \bigcup_{j = 1}^m g_j'(B_j)$. 
  Enligt $\mathsf{AC}$
  så finns det en urvalsfunktion $f$ som är definierad på mängden av alla banor av $G$. Därför kan vi definiera mängden $R \subset X$
  med 
  \[R \equiv \{f(\orbit_x) \; | \; x \in X\}.\]
  Från \hyperlink{lemma6.9.1}{lemma 5.9.1} så utgör $R$ en partition av $X$, det vill säga 
  \[X = \bigcup_{g \in G} gR.\]
  Då $G$ är en paradoxal grupp så kan två olika $g$ "väljas" i ekvationen ovan. För att använda detta faktum så inför vi en ny beteckning. 
  Låt 
  \[G(R) \equiv \bigcup_{g \in G} gR.\]
  Nu är $X = G(R)$ och eftersom $G$ är paradoxal så är 
  \[X = \bigcup_{i = 1}^n g_i(A_i(R)) \quad \text{och} \quad X = \bigcup_{j = 1}^m g_j'(B_j(R))\]
  där $A_i(R)$ definieras på samma sätt som $G(R)$, det vill säga
  \[A_i(R) \equiv \bigcup_{g \in A_i} gR\]
  och $B_j(R)$ definieras på ett liknande sätt.
\end{proof}

Vi börjar närma oss Banach-Tarski paradoxen. Om vi sätter $G = \text{SO}_3$ så är en sfär $\text{SO}_3$-paradoxal. Problemet är dock 
att vi har fixerade punkter på en sfär (punkterna som bildas då rotationsaxeln skär sfären) och därför kan vi inte tillämpa ovanstående sats. 
Dessutom vet inte om $\text{SO}_3$ är paradoxal eller inte! Nästa avsnitt kommer att ta upp Hausdorff paradoxen som är 
ett "specialfall" av Banach-Tarski paradoxen. 

\subsection{Frigrupp i \texorpdfstring{$\text{SO}_3$}{}}
Vi börjar med att definiera en sfär för att sedan gå över till ett viktigt lemma.
\begin{mydef}{}{}
  En \textit{2-sfär}, $S^2$, är en sfär i tre dimensioner. Det vill säga 
  \[S^2 \equiv \{(x, y, z) \; | \; x^2 + y^2 + z^2 = 1\}.\]
\end{mydef}

Anledningen till namnet 2-sfär och inte 3-sfär (som kanske känns naturligt då det är en 3D sfär) ligger i att dess yta är tvådimensionell.
En $S^n$ sfär definieras på ett analogt sätt.
Vi kommer endast att kolla på sfärar vars radie är ett. Detta eftersom alla andra sfärar är ekvivalenta upp till translationer och utvidgningar, 
de är \textit{homeomorfa} (eng. homeomorphic) som topologiska rum. Detta begrepp är inget som vi ska syssla med i denna text då det tillhör 
topologi. Förhoppningsvis (om tiden finns) så är detta ett område som vi i en senare text studerar mer ingående. 
Vi går vidare till ett viktigt lemma.

\hypertarget{lemma8.3.1}{}
\begin{mylemma}{}{}
  Det finns en delgrupp till $\text{SO}_3$ som är fri med rank 2.
\end{mylemma}

\begin{proof}
  Låt $\text{SO}_3$ verka på $S^2$ (det är trivialt att $\text{SO}_3$ verkar på $S^2$ då alla krav för gruppverkan uppfylls).
  Välj en $v = \arccos(1/3)$ och låt $\theta$ vara en rotation kring $x$ axeln och $\phi$ en rotation kring $z$ axeln. Då 
  $\sin(\arccos(1/3)) = \sqrt{1 - \frac{1}{3^2}} = \frac{2 \sqrt{2}}{3}$ och $\cos(\arccos(1/3)) = 1/3$ så kan, enligt \hyperlink{sats5.3.2}{sats 4.3.2},
  $\theta, \theta^{-1}$ och $\phi, \phi^{-1}$ skrivas som 
  \[
  \phi^{\pm 1} = 
  \begin{bmatrix}
    \frac{1}{3} & \mp \frac{2 \sqrt{2}}{3} & 0 \\
    \pm \frac{2 \sqrt{2}}{3} & \frac{1}{3} & 0 \\
    0 & 0 & 1
  \end{bmatrix}, \quad
  \theta^{\pm 1} = 
  \begin{bmatrix}
    1 & 0 & 0 \\
    0 & \frac{1}{3} & \pm \frac{2 \sqrt{2}}{3} \\
    0 & \mp \frac{2 \sqrt{2}}{3} & \frac{1}{3}
  \end{bmatrix}.
  \]
  Vi påstår att $\langle \phi, \theta \rangle$ är en frigrupp, det vill säga att varje icke tomt reducerat ord i $\langle \phi, \theta \rangle$ 
  inte är enhetselementet. Vi kommer att visa att $w \cdot [1, 0, 0] \neq [1, 0, 0]$ för alla reducerade ord $w$ som inte fixar $[1, 0, 0]$. 
  Detta görs genom att visa att $w \cdot [1, 0, 0] = [a, b\sqrt{2}, c]/3^k$ och sedan att $3$ inte delar $b \sqrt{2}$ så att $b \sqrt{2} \neq 0$ för 
  tre heltal $a, b, c$ och där $k$ är längden av $w$. Detta görs genom induktion på längden av $w$, det vill säga $k$. Då $k = 1$
  så är antigen $w = \theta^{\pm 1}$ eller $w = \phi^{\pm 1}$. Om $w = \theta^{\pm 1}$ så är $w \cdot [1, 0, 0] = [1, 0, 0]$ och $w$ är på 
  den önskade formen. Om $w = \phi^{\pm 1}$ så är 
  \[\phi^{\pm 1}
  \begin{bmatrix}
    1 \\
    0 \\
    0
  \end{bmatrix} = 
  \begin{bmatrix}
    \frac{1}{3} & \mp \frac{2 \sqrt{2}}{3} & 0 \\
    \pm \frac{2 \sqrt{2}}{3} & \frac{1}{3} & 0 \\
    0 & 0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    1 \\
    0 \\
    0
  \end{bmatrix} = 
  \frac{1}{3}
  \begin{bmatrix}
    1 \\
    \pm 2 \sqrt{2} \\
    0
  \end{bmatrix}.
  \]
  Vi drar slutsatsen att basfallet gäller. Antag att påståendet gäller för ett ord $w'$ med längen $k - 1$, det vill säga 
  $w'[1, 0, 0] = [a', b' \sqrt{2}, c']/3^{k - 1}$. Om vi multiplicerar $\phi^{\pm 1}$ till denna ekvation fås 
  \[ \frac{1}{3^{k - 1}}\phi^{\pm 1} 
  \begin{bmatrix}
    a' \\
    b' \sqrt{2} \\
    c'
  \end{bmatrix} = 
  \frac{1}{3^{k - 1}}
  \begin{bmatrix}
    \frac{1}{3} & \mp \frac{2 \sqrt{2}}{3} & 0 \\
    \pm \frac{2 \sqrt{2}}{3} & \frac{1}{3} & 0 \\
    0 & 0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    a' \\
    b' \sqrt{2} \\
    c'
  \end{bmatrix} = 
  \frac{1}{3^k}
  \begin{bmatrix}
    a' \mp 4b'  \\
    (b' \pm 2a')\sqrt{2} \\
    3c'
  \end{bmatrix}
  \]
  som är på den önskade formen. Om vi istället multiplicerar med $\theta^{\pm 1}$ till ekvationen fås 
  \[ \frac{1}{3^{k - 1}}\theta^{\pm 1} 
  \begin{bmatrix}
    a' \\
    b' \sqrt{2} \\
    c'
  \end{bmatrix} = 
  \frac{1}{3^k}
  \begin{bmatrix}
    3a' \\
    (b' \pm 2c')\sqrt{2} \\
    c' \mp 4b'
  \end{bmatrix}
  \]
  som är på den önskade formen.
  För att visa att heltalet $b$ i $[a, b \sqrt{2}, c]$ inte kan vara delbart med 3 så kan man börja med att notera att 
  ett godtyckligt ord i $\langle \phi, \theta \rangle$ börjar antigen på $\phi^{\pm 1}$ 
  eller på $\theta^{\pm 1}$. Det blir totalt 12 fall och i varje fall behöver man använda induktion och en massa matris multiplikation. 
  Detta blir väldigt kladdigt 
  och därför hoppar vi över dessa steg och tar detta som givet. Då 3 inte delar $b$ så kan inte $w \cdot [1, 0, 0]$ vara lika med $[1, 0, 0]$. 
  Detta slutför beviset.
\end{proof}

\begin{mytheo}{Hausdorff paradoxen}{}
  Det existerar en uppräknelig delmängd $D$ av $S^2$ så att $S^2 \setminus D$ är $\text{SO}_3$ paradoxal.
\end{mytheo}

\begin{proof}
  Enligt \hyperlink{lemma8.3.1}{lemma 7.3.1} så existerar det två element $\phi, \theta \in \text{SO}_3$ som genererar en frigrupp $F$
  av rank två. För varje reducerat ord innehållande $\phi$ och $\theta$ så finns det två fixerade punkter i $S^2$ där rotationsaxeln skär $S^2$. 
  Låt $D$ vara mängden av dessa fixerade punkter. Då det finns uppräkneligt många reducerade ord innehållande $\phi$ och $\theta$ så är $D$ uppräknelig. 
  Nu verkar $F$ på $S^2 \setminus D$ utan icke triviala fixerade punkter. Enligt \hyperlink{sats8.2.2}{sats 7.2.2} så är $F$ en paradoxal grupp.
  Enligt \hyperlink{sats8.3.2}{sats 7.2.3} så är $S^2 \setminus D$ $F$-paradoxal. Då elementen i multimängderna av $F$ som gör 
  $S^2 \setminus D$ paradoxal finns i $\text{SO}_3$ så är $S^2 \setminus D$ $\text{SO}_3$-paradoxal.
\end{proof}

Från och med nu definierar vi $F$ och $D$ precis som vi gjorde ovan. Vi vill nu generalisera denna paradox för att få Banach-Tarski paradoxen. 

\begin{mylemma}{}{}
  Det existerar en linje, $\ell$, som skär origo i $\mathbb{R}^3$ och som skär $S^2$ i två punkter som inte finns i $D$.
\end{mylemma}

\begin{proof}
  Då $S^2$ har ouppräkneligt många punkter och $D$ har uppräkneligt många punkter så existerar det en punkt $x \in S^2 \setminus D$.
  Då måste även $-x \in S^2 \setminus D$. Låt $\ell$ vara just den linjen som skär origo och $x$. 
\end{proof}

Från och med nu kommer $\ell$ stå för linjen ovan.

\hypertarget{sats8.2.3}{}
\begin{mytheo}{}{}
  Antag att det finns en rotation $\sigma$ runt $\ell$ så att elementen i $\{\sigma^i(D) \; | \; i \in \mathbb{N}\}$ är parvis disjunkta. 
  Då är $S^2 \setminus D$ $\text{SO}_3$-equidekomposibel med $S^2$ med två bitar.
\end{mytheo}

\begin{proof}
  Definiera $\sigma$ precis som vi gjorde ovan. Låt 
  \[\overline{D} \equiv \bigcup_{n = 1}^\infty \sigma^n(D).\]
  Vi noterar att $S^2 = \overline{D} \cup (S^2 \setminus \overline{D})$, som är equidekomposibel med 
  $\sigma(\overline{D}) \cup (S^2 \setminus \overline{D})$. Vi noterar dock att $\sigma(\overline{D}) = \overline{D} \setminus D$ så att 
  $\sigma(\overline{D}) \cup (S^2 \setminus \overline{D}) = (\overline{D} \setminus D) \cup (S^2 \setminus \overline{D}) = S^2 \setminus D$.
\end{proof}

Denna sats kan förstås intuitivt. Figuren nedan visar $S^2 \setminus D$.

\begin{center}
  \begin{tikzpicture}
    \shade[ball color = gray!40, opacity = 0.4] (0,0) circle (2cm);
    \draw (0,0) circle (2cm);
    \draw (-2,0) arc (180:360:2 and 0.6);
    \draw[dashed] (2,0) arc (0:180:2 and 0.6);

    \draw[rotate=20, fill=myblue, opacity=0.4] (0.2,0) ellipse (0.6 and 1.2);
    \fill[fill=black] (0,1) circle (1.5pt);
    \fill[fill=black] (0.3,0.7) circle (1.5pt);
    \fill[fill=black] (0,0.3) circle (1.5pt);
    \fill[fill=black] (0.4,-0.3) circle (1.5pt);
    \fill[fill=black] (0.2,-0.1) circle (1.5pt);

    \draw (0.5, -0.8) [bend right, line width = 0.3mm] to (2.5, 0) node at (2.7, 0) {$D$};

    \draw(0, 1) [bend left, -latex] to (-1, 1);
    \draw(0.3, 0.7) [bend left, -latex] to (-1, 0.7);
    \draw(0, 0.3) [bend left, -latex] to (-1, 0.3);
    \draw(0.4, -0.3) [bend left, -latex] to (-1, -0.3);
    \draw(0.2, -0.1) [bend left, -latex] to (-1, -0.1);

    \draw(1.5, 1) [bend right, -latex] to (0, 1);
    \draw(1.5, 0.7) [bend right, -latex] to (0.3, 0.7);
    \draw(1.5, 0.3) [bend right, -latex] to (0, 0.3);
    \draw(1.5, -0.3) [bend right, -latex] to (0.4,-0.3);
    \draw(1.5, -0.1) [bend right, -latex] to (0.2,-0.1);
  \end{tikzpicture}
\end{center}
Genom att rotera alla punkter så att punkterna i $D$ inte hamnar på en annan punkt i $D$ så kommer andra punkter i $S^2$ "fylla" ut dessa punkter 
i $D$. Men de punkter som "fyllde" i punkterna i $D$ är nu "tomma". Därför roterar vi igen så att dessa punkter blir ifyllda. Vi kan hålla på såhär 
tills alla punkter blir ifyllda då omkretsen för en cirkel är irrationell och därför finns det oändligt många punkter som kan fylla i 
de "tomma" punkterna. Man kan dra en liknelse mellan detta och Hillberts hotell. På så sätt kan vi 
skapa $S^2$ från $S^2 \setminus D$ med bara rotationer i $\text{SO}_3$.

Vi är nu redo att bevisa Banach-Tarski paradoxen. 
\begin{mytheo}{Banach-Tarski paradoxen}{}
  $S^2$ är $\text{SO}_3$-paradoxal.
\end{mytheo}

\begin{proof}
  Hausdorff paradoxen säger att $S^2 \setminus D$ är $\text{SO}_3$-paradoxal. Då $D$ är uppräknelig och $S^2$ är ouppräknelig så kan vi 
  hitta en vinkel som roterar alla punkter i $D$ till en annan punkt som inte finns i $D$. Enligt \hyperlink{sats8.2.3}{sats 7.3.2} så är då 
  $S^2 \setminus D$ $\text{SO}_3$-equidekomposibel med $S^2$. Då $S^2 \setminus D$ är paradoxal samtidigt som $S^2 \setminus$ är $\text{SO}_3$-equidekomposibel 
  så följer det att $S^2$ är $\text{SO}_3$ paradoxal från \hyperlink{sats8.2.1}{sats 7.2.1}.
\end{proof}
Då \hyperlink{lemma8.3.1}{lemma 7.3.1} är en förutsättning för paradoxen så kan vi dra slutsatsen att Banach-Tarski paradoxen inte 
fungerar på en cirkel. En grupp innehållande endast rotationer kring en axel är abelsk och har en alldeles för enkel struktur 
för att en frigrupp av rank 2 ska rymmas i den. Den minsta gruppen innehållande en kopia av en frigrupp av rank 2 är just $\text{SO}_3$.

Det finns en startkare version av denna paradox. För att bevisa den så behövs följande sats.

\begin{mytheo}{Banach-Schröder-Bernstein satsen}{}
  Antag att gruppen $G$ verkar på $X$. Om både $A \subseteq X$ och $B \subseteq X$ är $G$-equidekomposibla med en delmängd av den andra så är $A$
  $G$-equidel med $B$.
\end{mytheo}
\begin{proof}
  Låt $g \in G$ vara det elementet som gör att $A$ blir equidekomposibel med en delmängd av $B$, det vill säga $g(A) \subseteq B$.
  Låt $g' \in G$ vara det elementet som gör att $B$ blir equidekomposibel med en delmängd av $A$, det vill säga $g'(B) \subseteq A$.
  Låt 
  \[A_1 \equiv \bigcup_{i = 0}^\infty (g' \circ g)^i(A \setminus g'(B)).\]
  Då $g'(g(A)) \subseteq g'(B) \subseteq A$ så har vi med enkel induktion att $(g' \circ g)^i(A) \subseteq A$. Detta betyder att $A_1 \subseteq A$.
  Låt $A_2 = A \setminus A_1$, $B_1 = g(A_1) \subseteq B$, $B_2 = B \setminus B_1$. Vi ser att $A_1 = (A \setminus g'(B)) \cup (g' \circ g)(A_i)$. 
  Detta betyder att
  \begin{align*}
    A_2 &= A \setminus ((A \setminus g'(B)) \cup (g' \circ g)(A_1)) = g'(B) \cap ( A \setminus (g' \circ g)(A_1) ) \\
    &= g'(B) \setminus (g' \circ g)(A_1) = g'(B) \setminus g'(B_1) = g'(B_2).
  \end{align*}
  Vi alltså skära upp $A$ till $A_1$ och $A_2$ och sedan verka med $g$ på $A_1$ och $g'^{-1}$ på $A_2$ för att få $B$. 
\end{proof}

I beviset ovan användes faktumet att $C \setminus (A \cup B) = (C \setminus A) \cap (C \setminus B)$ och att $(B \setminus A) \cap C = (B \cap C) \setminus A$. 
I det första fallet kan man använda De Morgans lag, $\neg (P \vee  Q) \iff (\neg P) \wedge (\neg Q)$, och det andra fallet är trivialt att bevisa. 
Detta får läsaren göra.
\begin{mytheo}{Den starka versionen av Banach-Tarski paradoxen}{}
  Om $A, B \subset \mathbb{R}^3$ är begränsade mängder där båda har ett icke tomt inre så är $A$ och $B$ equidekomposibla.
\end{mytheo}

Innan vi bevisar denna sats så måste vi först reda ut några begrepp. Man kan säga att en \textit{begränsad mängd} är en mängd vars 
kardinalitet är ändlig. För läsare som är bekanta med metriska rum (till exempel Europaelever som läser kursen Linjär Cirkel)
så är en delmängd $S$ av ett metriskt rum $(M, d)$ begränsad om det existerar ett $r > 0$ så att för alla 
$s$ och $t$ i $S$ så är $d(s, t) < r$. Det finns dock olika definitioner av begränsade mängder inom olika områden i matematiken.
\textit{Det inre} är mängden av alla inre punkter i en delmängd $S$ av ett Euklidiskt rum. En punkt $x \in S$ är en inre punkt i $S$
om det existerar en boll centrerad i $x$ som $S$ innesluter. Detta kan generaliseras till topologiska rum genom att byta ut bollen med en öppen mängd.

\begin{proof}
  Med Banach-Schröder-Bernstein satsen så räcker det med att visa att $A$ är equidekomposibel med en delmängd av $B$ och vice versa. 
  Låt $L$ vara en boll i $B$. Med Banach-Tarski paradoxen och med induktion så kan vi skapa ändligt många kopior av $L$. Då $A$ är begränsad så 
  kan kan dessa kopior av $L$ placerar i $A$. Nu är $A$ unionen av alla dessa kopior av $L$. Nu är $A$ equidekomposibel med en delmängd av $B$, 
  nämligen $L$. Man kan replikera beviset för att visa att $B$ är equidekomposibel med en delmängd av $A$.
\end{proof}

Vi kan även dra följande följdsats.

\begin{mykol}{}{}
  En sfär i ett $n$-dimensionellt Euklidiskt rum är paradoxal för $n \geq 3$. 
\end{mykol}
\begin{proof}
  Vi bevisar detta med induktion. Basfallet, då $n = 3$, är redan bevisad. Skärningen (skärnings-"punkten") mellan en sfär i $n+1$ dimensioner 
  och ett plan är en sfär i $n$ dimensioner. Till exempel så är skärningen mellan ett plan i tre dimensioner och en vanlig sfär en cirkel. 
  Skär upp en sfär i $n+1$ dimensioner till sfärar i $n$ dimensioner. Enligt induktionsantagandet så kan vi duplicera alla dessa 
  sfärar i $n$ dimensioner. Vi kan nu bygga upp två $n+1$ sfärar genom att sätta ihop våra sfärar i $n$ dimensioner.
\end{proof}
Man förstå denna sats genom att inse att hela paradoxen ligger i att en frigrupp av rank 2 är inbäddad i $\text{SO}_3$. Då $\text{SO}_3$
är en delgrupp till $\text{SO}_n$ för $n \geq 4$ så är även en frigrupp av rank 2 inbäddad i dessa.


Då en $n$-sfär kan byggas upp med $n-1$-sfärar så kanske det känns rimligt att man kan duplicera $n-1$-sfären för att sedan bygga upp en $n$-sfär.
Denna metod fungerar dock inte då vi endast kan skapa ändligt många kopior av en sfär och en $n$-sfär består av oändligt många $n-1$-sfärar. 

\section{Diskussion}
Vi har nu härlett resultat som är helt ointuitiva, med Banach-Tarski paradoxen kan vi duplicera en sfär och 
med den starka versionen kan vi omvandla vilken figur som helst till en annan önskad figur. Vid första anblicken verkar detta resultat 
gå emot grundläggande matematik. Det är lätt att tro att volymen för alla bitar i dekompositionen måste addera upp till volynomen för hela 
sfären, och inte vara dubbelt så stor! Men faktumet är att Banach-Tarski paradoxen är formellt bevisad från fundamentala matematiska 
axiomer. Den går \textit{med} grundläggande matematik och inte \textit{emot}.

Om detta är fallet, varför benämns isåfall detta resultat för "paradox"? En paradox är inte ett påstående som är falsk, utan ett teoretiskt resultat 
som inte överensstämmer med det sunda förnuftet. Det går alltså bra att kalla Banach-Tarski paradoxen för en matematisk sats istället. 

Ska vi då acceptera denna paradox eller dra slutsatsen att våra antaganden är felaktiga? 
Om det finns något att skylla på så är det urvalsaxiomet ($\mathsf{AC}$). Utan $\mathsf{AC}$ så skulle \hyperlink{sats8.3.2}{sats 7.2.3}
inte gälla och hela paradoxen skulle falla. Det är dessutom $\mathsf{AC}$ som tillåter oss att skapa \textit{nollmängder} från en sfär, 
det vill säga mängder med Lebesguemått noll. Det är just dessa mängder som tillåter oss att dubbla volymen. 
Förstås så har vi i denna text endast visat \textit{ett} bevis av paradoxen, men det 
är bevisat att andra axiomer inte kan ge ett resultat av detta slag. 

Att fråga om $\mathsf{AC}$ verkligen ska vara ett axiom eller inte är i princip ekvivalent med att fråga om kungen i shack 
verkligen ska gå som den gör. Kungen i schack rör sig som den gör eftersom det gör spelet mer interesant att spela.
Det finns inte "en sann matematik". Matematik är en kollektion av resultat som följer logiskt från några grundantaganden, axiomer. 
Visst kan diskutera kring hur axiomer är relaterade till varandra, men vi kan aldrig säga vilket axiom som är "korrekt". 
Det enda vi kan göra är att bry oss mer om vissa axiomer än andra då de kan vara mer interesanta. 
I den egen "matematik värld" får du själv välja vilka axiomer du tycker är rimliga, precis som 
du i ditt eget shack spel får välja hur kungen rör sig för att göra spelet mer interesant. Men tillslut måste vi komma överens 
om något så att vi i slutändan spelar samma spel.

Kan vi då använda Banach-Tarski paradoxen i den verkliga världen? Förstås så används matematik för att modellera fysik, 
men varje model är ofullständig. En matematisk sfär med oändligt många punkter skiljer sig från en fysisk sfär som har 
ändligt många "punkter". Banach-Tarski paradoxen kräven en sfär med oändligt många punkter, som är omöjligt att skapa i den verkliga världen. 
Men fysiken överraskar oss ständigt med dess konstiga egenskaper. Kan detta vara en förklaring till varför det bildas fler partiklar
när vi kolliderar två partiklar? Kan den starka versionen av paradoxen förklara universums expansion?
\end{document}

%------------------VIKTIGT------------------
%FRÅGESTÄLLNING:::::: Kan en sfär i n dimensioner duplikeras?
%kan man på så sätt skapa en boll i en dimension större än den man började med??
%(t.ex. från 3d till 4d). Vad är det som orakar denna paradox? (denna fråga är dock trivial).
%kan detta hända i den riktiga världen?
%finns det ett enklare sätt att förstå detta utan att använda matte?
%https://en.wikipedia.org/wiki/N-sphere
https://en.wikipedia.org/wiki/Banach%E2%80%93Tarski_paradox#Obtaining_infinitely_many_balls_from_one'

%skriv även lite snabbt varför det inte går att duplikera en cirkel. 
% It leads to Bustany's Rule of Infinity: Infinity and Intuition do not mix.

%jag måste bevisa att skärningen mellan en platta, w=c, och en sfär i fyra dimensioner
%är en sfär i tre dimensioner. Sedan kan jag samla alla dessa 3d sfärar och dublicera dessa 
%och sammansätta dem till en ny 4d sfär. 

%kan jag skapa en 4d sfär från en 3d? Eftersom en 4d består av oändligt många 3d sfärar 
%(visa detta eller utgå bara från att skärningen mellan 4d och en platta blir 3d och bör 
%därför bestå av 3d) så kan jag bara dublicera oändligt många 3d sfärar och sedan sammansätta 
%dessa till en 4d. 

%Något annat coolt man kan skriva om??
%------------------VIKTIGT------------------
